{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b781c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/openfl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision\n",
    "import glob\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e79d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "root_dir = './'\n",
    "from torchvision import transforms\n",
    "\n",
    "normalize = T.Normalize(\n",
    "    mean=[0.4914, 0.4822, 0.4465],\n",
    "    std=[0.247, 0.243, 0.261]\n",
    ")\n",
    "\n",
    "augmentation = T.RandomApply(\n",
    "    [T.RandomHorizontalFlip(),\n",
    "     T.RandomCrop(32, padding=4)],\n",
    "    p=.5\n",
    ")\n",
    "\n",
    "# Compose transformations\n",
    "data_transform = transforms.Compose([\n",
    "  transforms.Resize(32),\n",
    "  transforms.ToTensor(),\n",
    "  augmentation,\n",
    "  normalize\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.Resize(32),\n",
    "  transforms.ToTensor(),\n",
    "  normalize\n",
    "])\n",
    "# Load MNIST dataset with transforms\n",
    "trainset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=data_transform)\n",
    "valset = torchvision.datasets.CIFAR10(root=root_dir, train=True, download=True, transform=test_transform)\n",
    "testset = torchvision.datasets.CIFAR10(root=root_dir, train=False, download=True, transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "246b7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "365985bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64655138",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_size = 0.2\n",
    "split = int(np.floor(valid_size * num_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b22fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "shuffle = True\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "add4ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, sampler=train_sampler, num_workers=2, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(valset, batch_size=128, sampler=valid_sampler, num_workers=2, drop_last=False)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, num_workers=2, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8483a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. classes: 10\n",
      "Classes:\n",
      " ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "Num. train samples: 50000\n",
      "Num. test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Get number of classes (we'll need it in the model)\n",
    "num_classes = len(trainset.classes)\n",
    "# Print dataset statistics\n",
    "print(f\"Num. classes: {num_classes}\")\n",
    "print(f\"Classes:\\n {trainset.classes}\")\n",
    "print(f\"Num. train samples: {len(trainset)}\")\n",
    "print(f\"Num. test samples: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60e08542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  truck (9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_example(img, label):\n",
    "    print('Label: ', trainset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "show_example(*trainset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78ad589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=(7,7), stride=(2,2), padding=(3,3), bias=False)\n",
    "resnet18.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "\n",
    "#MOMENTUM\n",
    "resnet18.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "\n",
    "resnet18.layer1[0].bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer1[0].bn2 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer1[1].bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer1[1].bn2 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "\n",
    "resnet18.layer2[0].bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer2[0].bn2 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer2[1].bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer2[1].bn2 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer2[0].downsample[1] = nn.GroupNorm(32, 128)\n",
    "\n",
    "resnet18.layer3[0].bn1 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer3[0].bn2 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer3[1].bn1 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer3[1].bn2 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer3[0].downsample[1] = nn.BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "\n",
    "resnet18.layer4[0].bn1 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer4[0].bn2 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer4[1].bn1 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer4[1].bn2 = nn.BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "resnet18.layer4[0].downsample[1] = nn.BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
    "\n",
    "# Create the model\n",
    "model = resnet18\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ad9899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-6.2180e-02,  7.0014e-02, -1.7035e-02,  ...,  1.5838e-02,\n",
       "            -2.2939e-02,  5.2414e-02],\n",
       "           [-4.3869e-02, -6.0750e-02, -2.4431e-02,  ..., -7.5639e-02,\n",
       "            -2.1741e-02,  1.6168e-02],\n",
       "           [-3.1244e-02, -1.4783e-02, -5.4932e-02,  ..., -1.7755e-02,\n",
       "             1.4109e-02, -5.7983e-02],\n",
       "           ...,\n",
       "           [-3.5194e-02, -2.4709e-02, -3.9488e-02,  ...,  2.0835e-02,\n",
       "            -5.3458e-02,  3.5728e-02],\n",
       "           [-7.7013e-02, -9.4114e-05, -4.8205e-02,  ..., -2.7180e-02,\n",
       "             1.7816e-02, -6.5311e-02],\n",
       "           [ 3.2495e-02,  5.6344e-02, -2.8626e-02,  ...,  2.7954e-02,\n",
       "             3.6116e-02,  2.7394e-02]],\n",
       " \n",
       "          [[ 2.8217e-02, -2.6394e-02, -4.3001e-02,  ..., -6.3680e-02,\n",
       "             2.9411e-02,  1.5369e-02],\n",
       "           [-7.9128e-02,  5.5824e-02, -8.1355e-02,  ...,  2.8385e-02,\n",
       "             7.9422e-02,  2.1540e-02],\n",
       "           [-2.3748e-02,  2.5476e-02,  3.2575e-02,  ..., -7.4231e-02,\n",
       "             3.4369e-02, -4.9388e-02],\n",
       "           ...,\n",
       "           [ 4.5329e-03, -2.7298e-02, -6.3192e-02,  ..., -2.5128e-03,\n",
       "             4.8579e-02,  1.4636e-02],\n",
       "           [-2.5337e-02, -5.2324e-02, -7.0155e-02,  ..., -2.9024e-02,\n",
       "            -5.7334e-02,  6.8462e-02],\n",
       "           [ 4.2313e-02, -3.8105e-02,  3.1313e-02,  ..., -5.2841e-02,\n",
       "             7.0852e-02,  6.0447e-02]],\n",
       " \n",
       "          [[-2.8375e-02, -4.3396e-02,  2.5221e-02,  ...,  1.1879e-02,\n",
       "            -4.3923e-02, -3.5493e-03],\n",
       "           [ 6.0403e-03,  6.1751e-02,  6.4224e-03,  ...,  5.6777e-02,\n",
       "             6.2298e-02, -6.1149e-02],\n",
       "           [ 5.3800e-02,  8.7818e-03, -7.2281e-02,  ..., -1.3019e-02,\n",
       "            -1.6301e-02,  2.3082e-02],\n",
       "           ...,\n",
       "           [ 3.0046e-02, -4.4362e-02, -7.6269e-03,  ..., -4.8358e-02,\n",
       "            -5.2087e-02, -2.9359e-02],\n",
       "           [-7.7495e-02, -2.1996e-02,  6.6804e-02,  ...,  4.1302e-02,\n",
       "             2.9244e-02,  3.6054e-02],\n",
       "           [ 7.8840e-02, -6.1735e-02,  6.9810e-02,  ..., -1.5811e-02,\n",
       "             2.0139e-02, -6.0912e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.9527e-02, -4.0012e-02,  2.5566e-02,  ..., -2.0100e-02,\n",
       "             3.9669e-02, -6.4543e-02],\n",
       "           [ 6.9047e-02, -1.6713e-02, -1.1809e-03,  ...,  5.3788e-02,\n",
       "             6.8062e-02, -7.4759e-02],\n",
       "           [ 3.8119e-02,  2.7045e-02,  7.8661e-02,  ...,  7.6307e-02,\n",
       "            -3.2950e-02,  5.4086e-02],\n",
       "           ...,\n",
       "           [-2.3911e-02, -7.6058e-02,  2.9670e-02,  ...,  7.6561e-03,\n",
       "            -5.6958e-02, -4.6545e-02],\n",
       "           [-3.0133e-02, -4.5333e-03, -4.6355e-02,  ...,  7.0181e-02,\n",
       "            -9.1448e-03,  4.9611e-02],\n",
       "           [-2.9692e-02,  5.8243e-02, -1.1133e-02,  ...,  6.5868e-02,\n",
       "             5.9079e-02,  3.4919e-02]],\n",
       " \n",
       "          [[ 4.6562e-02,  6.9027e-02,  6.9170e-02,  ...,  4.7995e-02,\n",
       "             7.2308e-03, -7.4461e-02],\n",
       "           [ 2.2062e-02, -1.3184e-02,  7.0052e-02,  ..., -1.0854e-02,\n",
       "             6.5876e-02,  6.6737e-02],\n",
       "           [ 6.1579e-02, -1.0790e-02,  2.2471e-02,  ..., -3.0042e-02,\n",
       "             6.5902e-02,  4.9801e-02],\n",
       "           ...,\n",
       "           [-6.3393e-02, -2.3238e-02, -6.5195e-02,  ..., -2.6815e-02,\n",
       "            -4.4165e-02, -6.5269e-02],\n",
       "           [ 6.5991e-02,  6.9097e-02, -7.7754e-03,  ..., -5.9040e-02,\n",
       "            -2.5597e-02,  7.8002e-02],\n",
       "           [ 6.2576e-02,  4.8503e-02, -2.9931e-02,  ...,  4.0980e-02,\n",
       "            -3.2649e-02,  5.1809e-02]],\n",
       " \n",
       "          [[ 7.6504e-02, -2.3080e-02, -5.6439e-02,  ..., -6.9289e-02,\n",
       "             6.3772e-02,  2.8169e-02],\n",
       "           [-7.1584e-02,  3.2360e-02, -5.2844e-02,  ...,  5.2782e-02,\n",
       "            -9.5946e-03,  2.2095e-02],\n",
       "           [-6.5520e-02,  3.4059e-02, -4.1544e-02,  ..., -5.8064e-02,\n",
       "            -8.1046e-02,  3.5905e-02],\n",
       "           ...,\n",
       "           [ 1.2642e-02,  1.3397e-03, -7.9700e-02,  ..., -2.6397e-02,\n",
       "            -1.0202e-02, -3.1185e-02],\n",
       "           [-1.3828e-02, -3.2295e-02, -1.6248e-02,  ..., -1.7455e-02,\n",
       "             7.3561e-02,  2.2226e-02],\n",
       "           [ 1.8219e-02, -3.2558e-02, -3.1012e-03,  ..., -2.4851e-02,\n",
       "             3.0170e-02, -2.1356e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.3478e-02, -3.6745e-02, -3.4869e-02,  ...,  7.0444e-02,\n",
       "             6.3277e-02,  5.4021e-03],\n",
       "           [ 5.3138e-02,  7.8435e-02, -3.5519e-02,  ..., -4.3987e-02,\n",
       "            -7.4559e-02, -5.0509e-02],\n",
       "           [-3.1702e-02, -4.4981e-02, -5.2708e-02,  ...,  6.6041e-02,\n",
       "             6.9469e-02, -5.7623e-03],\n",
       "           ...,\n",
       "           [-3.7978e-02, -5.6585e-02, -4.2485e-02,  ..., -2.6306e-02,\n",
       "             2.7271e-02,  9.5697e-03],\n",
       "           [-3.8310e-02, -2.9078e-02, -5.6573e-02,  ..., -4.8529e-02,\n",
       "            -7.5861e-02,  8.3139e-03],\n",
       "           [ 7.7988e-02,  7.8980e-02,  1.1281e-02,  ...,  3.7153e-02,\n",
       "            -6.8904e-02, -1.6920e-02]],\n",
       " \n",
       "          [[-1.6334e-02,  8.1093e-02, -7.4607e-02,  ..., -6.4061e-02,\n",
       "            -5.0297e-02,  1.1761e-02],\n",
       "           [-1.0615e-02,  2.3089e-02, -4.7078e-02,  ..., -1.5195e-02,\n",
       "            -2.2623e-02,  6.8346e-02],\n",
       "           [ 7.8111e-02, -3.6945e-02, -1.0444e-02,  ...,  4.9022e-02,\n",
       "            -5.0946e-02, -3.1502e-02],\n",
       "           ...,\n",
       "           [ 2.3124e-02,  3.4451e-02,  7.5364e-02,  ...,  3.9050e-02,\n",
       "             8.1883e-02,  8.0343e-02],\n",
       "           [ 2.8811e-02,  3.6848e-02,  8.0972e-02,  ...,  4.0566e-02,\n",
       "            -1.6175e-02,  7.0448e-02],\n",
       "           [ 2.2782e-02,  7.4987e-02, -7.1160e-02,  ..., -9.1783e-03,\n",
       "             7.6096e-02,  3.8425e-02]],\n",
       " \n",
       "          [[ 1.4726e-02, -5.3543e-02, -4.4487e-02,  ..., -2.5287e-02,\n",
       "             1.6077e-03, -2.1701e-02],\n",
       "           [-2.1554e-02, -7.1548e-02, -3.3221e-02,  ..., -6.0909e-02,\n",
       "            -1.4694e-02, -2.6512e-02],\n",
       "           [-1.7926e-02,  8.9318e-03,  1.4698e-02,  ..., -4.2894e-02,\n",
       "            -7.8542e-02, -6.5063e-02],\n",
       "           ...,\n",
       "           [ 9.4787e-03, -5.6283e-02, -6.7976e-02,  ...,  8.4024e-03,\n",
       "             1.9689e-02, -7.3968e-02],\n",
       "           [-7.1110e-02, -2.5576e-02,  1.5660e-02,  ..., -3.8350e-02,\n",
       "             7.2438e-02, -2.3961e-02],\n",
       "           [-2.1229e-02, -4.8516e-02, -4.0719e-02,  ..., -3.5721e-02,\n",
       "            -4.6069e-02, -1.4573e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.5265e-02,  3.6295e-03, -5.1850e-02,  ..., -1.9255e-02,\n",
       "            -2.8524e-02,  3.5774e-02],\n",
       "           [ 7.9058e-02,  3.5099e-02,  7.6591e-04,  ..., -2.6748e-02,\n",
       "             5.1975e-02, -3.0598e-03],\n",
       "           [-7.3818e-02,  6.3126e-02, -3.7273e-02,  ...,  2.8123e-02,\n",
       "            -8.0659e-02,  7.8629e-02],\n",
       "           ...,\n",
       "           [-4.1558e-02, -3.0523e-02,  9.8699e-03,  ..., -4.3884e-02,\n",
       "            -5.4197e-02, -6.5440e-02],\n",
       "           [ 1.4888e-02,  5.6168e-02, -2.1262e-02,  ...,  6.1635e-02,\n",
       "            -5.4703e-02, -4.3429e-02],\n",
       "           [ 5.5636e-02, -3.6733e-02, -1.3172e-03,  ..., -6.3499e-02,\n",
       "            -5.0189e-02,  6.6825e-02]],\n",
       " \n",
       "          [[ 1.1698e-02,  1.9618e-02,  7.7247e-02,  ...,  1.9331e-02,\n",
       "             5.3275e-02, -3.2834e-02],\n",
       "           [ 2.9056e-02,  6.6245e-03, -6.0768e-02,  ...,  3.7821e-02,\n",
       "            -2.3573e-02,  1.8215e-02],\n",
       "           [-3.3169e-02,  3.6927e-02,  3.1290e-02,  ...,  6.9283e-02,\n",
       "             6.2473e-02, -3.0924e-03],\n",
       "           ...,\n",
       "           [-3.0886e-02,  1.0363e-02,  3.3388e-02,  ..., -3.4763e-02,\n",
       "            -2.8438e-02,  3.9878e-02],\n",
       "           [ 3.0485e-02,  2.4052e-02, -7.8759e-03,  ...,  6.0429e-02,\n",
       "             4.4447e-02,  6.1420e-02],\n",
       "           [ 6.1022e-02,  7.0557e-02,  6.3588e-03,  ...,  3.7190e-02,\n",
       "             1.4713e-02,  2.5323e-02]],\n",
       " \n",
       "          [[-7.9859e-03,  1.0434e-02, -4.6193e-02,  ..., -5.5026e-02,\n",
       "             6.0204e-02, -5.4667e-02],\n",
       "           [ 4.1834e-03,  7.9205e-02, -5.8310e-02,  ..., -3.8006e-02,\n",
       "            -2.5310e-02, -4.6564e-02],\n",
       "           [ 3.0690e-02,  1.4097e-03,  5.9422e-02,  ..., -7.0626e-02,\n",
       "            -8.0302e-03, -2.1040e-04],\n",
       "           ...,\n",
       "           [-6.9321e-02,  4.8281e-02, -2.8776e-02,  ..., -4.8334e-02,\n",
       "             4.6004e-02, -6.7111e-02],\n",
       "           [ 5.2126e-02,  6.5274e-02,  3.0580e-02,  ..., -3.0265e-02,\n",
       "            -4.9927e-03,  3.2777e-02],\n",
       "           [-1.6122e-02,  2.6510e-02, -3.3130e-03,  ...,  7.2953e-02,\n",
       "            -6.9986e-02, -7.4412e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.5528e-02,  6.9586e-02,  7.9128e-02,  ...,  2.8261e-02,\n",
       "            -1.9247e-02, -3.5530e-02],\n",
       "           [ 4.0290e-02, -4.3531e-02, -6.6896e-02,  ..., -7.7615e-02,\n",
       "             1.6180e-02, -3.6552e-02],\n",
       "           [-8.7384e-03,  7.4358e-02, -3.9581e-02,  ...,  7.8015e-02,\n",
       "             5.3924e-02, -4.7182e-02],\n",
       "           ...,\n",
       "           [ 8.0369e-02, -5.6400e-03, -7.5257e-02,  ..., -6.3040e-02,\n",
       "             3.6812e-02, -6.5490e-02],\n",
       "           [ 3.1457e-02,  4.7679e-02, -3.5097e-02,  ...,  1.8306e-02,\n",
       "            -2.3661e-02,  4.0282e-03],\n",
       "           [ 3.3567e-02, -6.3980e-02,  6.0338e-02,  ...,  2.5631e-02,\n",
       "             2.2075e-02,  1.0390e-02]],\n",
       " \n",
       "          [[ 6.1596e-02, -3.1398e-02, -2.4327e-02,  ..., -1.2880e-02,\n",
       "            -1.2421e-02, -2.7120e-02],\n",
       "           [-5.2497e-02,  4.7823e-02, -3.5524e-02,  ..., -2.7265e-02,\n",
       "             2.2244e-02,  5.1194e-02],\n",
       "           [-2.4514e-02,  6.9427e-03,  6.6505e-02,  ...,  7.3713e-02,\n",
       "             4.6677e-02, -6.9113e-02],\n",
       "           ...,\n",
       "           [ 6.7258e-02,  2.3133e-02,  8.1302e-02,  ...,  6.0022e-02,\n",
       "             7.6795e-02,  6.5630e-03],\n",
       "           [ 5.6777e-02, -3.4992e-02,  7.7371e-02,  ..., -2.5004e-02,\n",
       "             4.9931e-02, -1.1918e-02],\n",
       "           [-5.1733e-02,  4.6111e-02,  4.0623e-02,  ..., -1.4327e-02,\n",
       "            -1.3190e-02,  1.9671e-02]],\n",
       " \n",
       "          [[-6.4639e-02, -2.4617e-02, -1.1383e-02,  ..., -2.0393e-04,\n",
       "            -2.0159e-02,  2.6558e-02],\n",
       "           [ 2.2801e-02,  4.2819e-02, -5.8280e-02,  ...,  6.9954e-02,\n",
       "             3.7449e-02,  3.6796e-02],\n",
       "           [ 2.6256e-02, -8.8410e-03,  5.1200e-02,  ...,  6.2554e-02,\n",
       "            -6.0435e-02,  2.2820e-02],\n",
       "           ...,\n",
       "           [ 1.6150e-02,  1.2055e-02, -4.0357e-02,  ..., -7.6503e-02,\n",
       "             2.9054e-02,  4.1243e-02],\n",
       "           [-5.0585e-02, -2.7100e-02,  6.4525e-02,  ...,  3.5959e-02,\n",
       "             2.0589e-02,  5.9599e-02],\n",
       "           [ 2.2353e-02, -5.2266e-02, -3.2813e-02,  ..., -4.8011e-02,\n",
       "             5.5412e-02, -4.2987e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.3150e-02,  4.7496e-02,  6.0615e-02,  ..., -4.5895e-02,\n",
       "            -7.0467e-02, -1.5208e-02],\n",
       "           [-7.7292e-02, -7.2382e-03, -5.3361e-02,  ..., -4.4792e-02,\n",
       "            -5.8612e-02,  4.2375e-02],\n",
       "           [ 6.7503e-02,  6.0440e-02,  3.9269e-02,  ..., -8.1062e-02,\n",
       "             7.6202e-02, -5.1371e-02],\n",
       "           ...,\n",
       "           [-5.4211e-02,  2.4934e-02,  4.1624e-02,  ..., -3.1614e-03,\n",
       "             5.6482e-02, -7.9447e-02],\n",
       "           [-5.2950e-02, -6.0394e-02,  6.8000e-03,  ..., -3.1733e-02,\n",
       "             7.7860e-02,  2.2392e-02],\n",
       "           [-7.3363e-02,  7.1827e-02,  5.3601e-02,  ...,  1.2269e-02,\n",
       "            -1.6023e-02,  3.3893e-03]],\n",
       " \n",
       "          [[ 5.9622e-02, -2.3329e-02, -8.4150e-03,  ...,  7.7382e-02,\n",
       "            -7.3683e-04,  1.5495e-02],\n",
       "           [ 1.8271e-02,  8.3736e-03, -3.8168e-02,  ...,  2.6246e-02,\n",
       "            -1.7762e-02, -4.5218e-02],\n",
       "           [ 4.4394e-02, -5.5212e-04, -5.9864e-02,  ...,  8.0385e-02,\n",
       "             1.8261e-02, -4.5424e-02],\n",
       "           ...,\n",
       "           [ 3.6249e-02, -1.6414e-02, -6.9351e-03,  ...,  2.3364e-02,\n",
       "             4.7273e-02,  7.4317e-02],\n",
       "           [-1.1382e-02,  8.2136e-02, -4.0763e-02,  ...,  3.6775e-02,\n",
       "             9.9313e-03,  3.8397e-02],\n",
       "           [-5.7229e-02,  5.7534e-03, -3.3821e-02,  ...,  6.4560e-02,\n",
       "            -6.5385e-02, -3.7973e-02]],\n",
       " \n",
       "          [[-4.1516e-02,  4.9163e-02,  4.9554e-02,  ..., -2.6944e-03,\n",
       "             4.3373e-02,  1.0774e-02],\n",
       "           [ 8.0768e-02, -4.9100e-02, -2.3684e-02,  ...,  4.2696e-02,\n",
       "            -2.0711e-02,  4.9585e-02],\n",
       "           [ 6.6539e-02, -3.0929e-03,  7.9094e-02,  ..., -6.5071e-02,\n",
       "            -6.1583e-02, -8.7570e-03],\n",
       "           ...,\n",
       "           [ 3.2646e-02,  1.1624e-02, -4.0137e-02,  ...,  5.4462e-02,\n",
       "             3.6137e-02,  1.1214e-02],\n",
       "           [-5.5060e-02, -4.3979e-02,  5.3029e-02,  ..., -1.7418e-02,\n",
       "            -7.1119e-02,  6.1326e-02],\n",
       "           [-2.5383e-02, -4.6094e-02, -6.3751e-02,  ..., -5.0012e-02,\n",
       "             1.7842e-04,  2.3460e-03]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0252, -0.0225,  0.0225],\n",
       "           [ 0.0405,  0.0491,  0.0085],\n",
       "           [-0.0582,  0.0909, -0.0590]],\n",
       " \n",
       "          [[ 0.0064,  0.0762, -0.0884],\n",
       "           [-0.0658,  0.0191,  0.1772],\n",
       "           [ 0.0099,  0.0147, -0.0092]],\n",
       " \n",
       "          [[-0.0799, -0.0216,  0.0239],\n",
       "           [ 0.0782,  0.0421,  0.0136],\n",
       "           [-0.0106, -0.0484,  0.0162]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0039, -0.0004, -0.0235],\n",
       "           [ 0.0598,  0.1167, -0.0482],\n",
       "           [ 0.1327, -0.0223, -0.0135]],\n",
       " \n",
       "          [[ 0.0238, -0.0140, -0.0850],\n",
       "           [-0.0146, -0.0293,  0.0335],\n",
       "           [ 0.0848,  0.0571,  0.0015]],\n",
       " \n",
       "          [[-0.0757,  0.0178, -0.0341],\n",
       "           [-0.0025, -0.1170, -0.0182],\n",
       "           [ 0.0012,  0.0342, -0.0466]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0588,  0.1024,  0.0259],\n",
       "           [ 0.0711,  0.0154,  0.0169],\n",
       "           [ 0.0126, -0.0394, -0.0069]],\n",
       " \n",
       "          [[ 0.0898,  0.0821, -0.0221],\n",
       "           [-0.0286, -0.0634,  0.0008],\n",
       "           [-0.0856,  0.0502, -0.0375]],\n",
       " \n",
       "          [[ 0.0774,  0.0131,  0.0476],\n",
       "           [ 0.0961, -0.0035, -0.0217],\n",
       "           [-0.0575,  0.0006, -0.0210]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0112, -0.0452, -0.1503],\n",
       "           [-0.0505,  0.0158,  0.0832],\n",
       "           [-0.0267,  0.0369,  0.0558]],\n",
       " \n",
       "          [[ 0.0313, -0.0014, -0.0949],\n",
       "           [ 0.0269, -0.0263,  0.0679],\n",
       "           [ 0.0128,  0.0266, -0.0299]],\n",
       " \n",
       "          [[ 0.0878, -0.0897, -0.0588],\n",
       "           [ 0.0825, -0.0236,  0.0557],\n",
       "           [ 0.0145, -0.0258, -0.0064]]],\n",
       " \n",
       " \n",
       "         [[[-0.0039,  0.0734,  0.0013],\n",
       "           [ 0.1360, -0.0143, -0.0092],\n",
       "           [-0.0862, -0.0145, -0.1059]],\n",
       " \n",
       "          [[ 0.0546,  0.0234, -0.0015],\n",
       "           [ 0.0603, -0.0116,  0.0478],\n",
       "           [ 0.0522,  0.0237, -0.0125]],\n",
       " \n",
       "          [[-0.0128,  0.0171,  0.0005],\n",
       "           [-0.0009, -0.0336,  0.0862],\n",
       "           [-0.0900, -0.1162,  0.0831]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1035,  0.0391, -0.0118],\n",
       "           [-0.1333, -0.0736, -0.0437],\n",
       "           [-0.0376,  0.0401, -0.0488]],\n",
       " \n",
       "          [[-0.0685,  0.1476,  0.1113],\n",
       "           [ 0.0131,  0.0184,  0.0020],\n",
       "           [ 0.0512,  0.0046, -0.0400]],\n",
       " \n",
       "          [[ 0.0235,  0.0587,  0.0028],\n",
       "           [-0.0418,  0.0061,  0.0567],\n",
       "           [-0.0694,  0.0185,  0.0024]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0383, -0.0990, -0.1069],\n",
       "           [ 0.0298, -0.0681,  0.0038],\n",
       "           [-0.0774, -0.0577, -0.0799]],\n",
       " \n",
       "          [[-0.0200, -0.0018, -0.0129],\n",
       "           [ 0.0612,  0.0239,  0.0557],\n",
       "           [-0.0398, -0.0702, -0.0570]],\n",
       " \n",
       "          [[ 0.1171, -0.0419,  0.0500],\n",
       "           [-0.1210,  0.0838, -0.0056],\n",
       "           [-0.0066, -0.0076,  0.0088]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0196, -0.0398,  0.0169],\n",
       "           [-0.0450, -0.0514,  0.0234],\n",
       "           [-0.0447, -0.0019, -0.0173]],\n",
       " \n",
       "          [[-0.0302, -0.0884, -0.0373],\n",
       "           [ 0.0524, -0.0514,  0.0500],\n",
       "           [-0.0062,  0.1062,  0.0321]],\n",
       " \n",
       "          [[ 0.0514,  0.0030, -0.0299],\n",
       "           [ 0.0544,  0.0468,  0.2053],\n",
       "           [ 0.1209, -0.0624, -0.0465]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0043,  0.0111, -0.0376],\n",
       "           [ 0.0708, -0.0055, -0.0292],\n",
       "           [ 0.0185,  0.0272, -0.0021]],\n",
       " \n",
       "          [[-0.0135, -0.0202,  0.0060],\n",
       "           [-0.0894,  0.0350,  0.0118],\n",
       "           [ 0.0466,  0.0518, -0.0231]],\n",
       " \n",
       "          [[-0.0746, -0.0120, -0.0060],\n",
       "           [-0.0290, -0.0148,  0.0045],\n",
       "           [ 0.1427,  0.1091, -0.0865]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0003,  0.0904,  0.0035],\n",
       "           [ 0.0375, -0.0032,  0.0623],\n",
       "           [ 0.0028,  0.1344,  0.1323]],\n",
       " \n",
       "          [[ 0.0528,  0.0140,  0.0368],\n",
       "           [ 0.0379, -0.0669,  0.0304],\n",
       "           [ 0.0122,  0.0416,  0.0197]],\n",
       " \n",
       "          [[ 0.0132, -0.1030,  0.0129],\n",
       "           [-0.0616,  0.0984,  0.0425],\n",
       "           [-0.0671,  0.0325, -0.0010]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1172, -0.1304, -0.1505],\n",
       "           [-0.0948,  0.0367, -0.0309],\n",
       "           [ 0.0240,  0.0329, -0.0804]],\n",
       " \n",
       "          [[ 0.0540, -0.0246, -0.0051],\n",
       "           [ 0.0688, -0.0071,  0.0497],\n",
       "           [ 0.0894,  0.0177,  0.0032]],\n",
       " \n",
       "          [[-0.0140, -0.1307,  0.0254],\n",
       "           [-0.0477, -0.0143, -0.0888],\n",
       "           [ 0.1048,  0.0098, -0.0553]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1382,  0.0224,  0.0762],\n",
       "           [-0.0263,  0.0222,  0.0125],\n",
       "           [-0.0227,  0.0261, -0.0234]],\n",
       " \n",
       "          [[ 0.0194, -0.0147,  0.0475],\n",
       "           [-0.0410, -0.0657, -0.1018],\n",
       "           [ 0.0124, -0.0095, -0.0935]],\n",
       " \n",
       "          [[ 0.0360, -0.0378,  0.0518],\n",
       "           [ 0.0547,  0.0789,  0.0517],\n",
       "           [ 0.1104, -0.0005,  0.0306]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0647,  0.0418,  0.0403],\n",
       "           [-0.0534, -0.0769,  0.1206],\n",
       "           [-0.0574,  0.0221, -0.0583]],\n",
       " \n",
       "          [[-0.1253,  0.1256, -0.0937],\n",
       "           [-0.1001,  0.0669,  0.1032],\n",
       "           [ 0.0229,  0.0055,  0.0889]],\n",
       " \n",
       "          [[ 0.0271, -0.0052,  0.0145],\n",
       "           [ 0.0386, -0.1079, -0.0773],\n",
       "           [-0.0850,  0.0416, -0.0162]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0074, -0.0097, -0.0083],\n",
       "           [-0.0529,  0.0108,  0.0076],\n",
       "           [-0.0775,  0.0256, -0.0585]],\n",
       " \n",
       "          [[ 0.0506, -0.0352, -0.0287],\n",
       "           [-0.0629, -0.0596, -0.0538],\n",
       "           [ 0.0704, -0.0629,  0.0515]],\n",
       " \n",
       "          [[ 0.0447,  0.0667,  0.0654],\n",
       "           [-0.0504, -0.0309, -0.0890],\n",
       "           [ 0.0258, -0.0567,  0.0276]]],\n",
       " \n",
       " \n",
       "         [[[-0.1195, -0.1061, -0.0738],\n",
       "           [ 0.0074,  0.0066, -0.1303],\n",
       "           [ 0.0792,  0.0737,  0.0575]],\n",
       " \n",
       "          [[ 0.0106, -0.0528,  0.0005],\n",
       "           [ 0.1007, -0.0254,  0.0137],\n",
       "           [ 0.1151, -0.0207,  0.0068]],\n",
       " \n",
       "          [[ 0.0768, -0.0322,  0.0017],\n",
       "           [ 0.0076,  0.0303, -0.0840],\n",
       "           [-0.0400, -0.0781, -0.0084]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1464, -0.0814, -0.0273],\n",
       "           [ 0.0387, -0.0311, -0.0551],\n",
       "           [ 0.0005, -0.0054,  0.0181]],\n",
       " \n",
       "          [[ 0.0841,  0.0465, -0.0467],\n",
       "           [-0.0404,  0.0248,  0.0165],\n",
       "           [-0.0448, -0.0285, -0.0050]],\n",
       " \n",
       "          [[-0.0171,  0.0724,  0.0382],\n",
       "           [-0.0213,  0.0643,  0.0726],\n",
       "           [ 0.0810, -0.0756, -0.0838]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0217,  0.0849, -0.0141],\n",
       "           [ 0.0597, -0.0258,  0.0050],\n",
       "           [-0.0604, -0.1804,  0.0297]],\n",
       " \n",
       "          [[ 0.1121, -0.0178,  0.0254],\n",
       "           [ 0.0138, -0.0202, -0.1390],\n",
       "           [ 0.0701,  0.0003,  0.1143]],\n",
       " \n",
       "          [[ 0.0122,  0.0183,  0.0997],\n",
       "           [ 0.0347,  0.0490,  0.0354],\n",
       "           [-0.1165, -0.0232,  0.0296]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0088,  0.0780, -0.0156],\n",
       "           [ 0.0389,  0.0883,  0.0881],\n",
       "           [-0.0873, -0.0048, -0.0283]],\n",
       " \n",
       "          [[-0.0176,  0.1073, -0.0033],\n",
       "           [-0.0597,  0.0132,  0.0934],\n",
       "           [ 0.0861, -0.0104,  0.1035]],\n",
       " \n",
       "          [[-0.0479,  0.0702, -0.1083],\n",
       "           [ 0.0697, -0.1390,  0.0438],\n",
       "           [-0.0520,  0.0447, -0.0553]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0409,  0.0029, -0.0652],\n",
       "           [-0.0169,  0.0636,  0.0319],\n",
       "           [-0.0766,  0.0193, -0.0338]],\n",
       " \n",
       "          [[ 0.0070,  0.0629,  0.0574],\n",
       "           [ 0.0499,  0.0662, -0.1280],\n",
       "           [ 0.0747,  0.0438, -0.0913]],\n",
       " \n",
       "          [[-0.0260, -0.0330,  0.0393],\n",
       "           [-0.0859, -0.0120,  0.0011],\n",
       "           [ 0.0828,  0.0740, -0.0154]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0147,  0.0737,  0.0075],\n",
       "           [-0.0719, -0.0253, -0.0032],\n",
       "           [ 0.0795,  0.0179, -0.0123]],\n",
       " \n",
       "          [[ 0.0221, -0.0330,  0.0469],\n",
       "           [ 0.0017, -0.0189,  0.0099],\n",
       "           [-0.0665,  0.0300,  0.0145]],\n",
       " \n",
       "          [[-0.0674, -0.0610, -0.0390],\n",
       "           [ 0.0284,  0.0074, -0.0068],\n",
       "           [ 0.0363, -0.0005,  0.0010]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0284,  0.1223, -0.0235],\n",
       "           [ 0.1172,  0.0135, -0.0191],\n",
       "           [ 0.0322,  0.0597,  0.0413]],\n",
       " \n",
       "          [[ 0.1264,  0.0094, -0.0047],\n",
       "           [ 0.0433,  0.0673,  0.0497],\n",
       "           [ 0.0193, -0.0942,  0.0644]],\n",
       " \n",
       "          [[ 0.0489,  0.0817, -0.0726],\n",
       "           [-0.0257,  0.0117, -0.0419],\n",
       "           [-0.0040, -0.1048,  0.0756]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0280, -0.0282,  0.0401],\n",
       "           [ 0.0725, -0.0265,  0.0895],\n",
       "           [ 0.1432,  0.0133, -0.0232]],\n",
       " \n",
       "          [[-0.0487, -0.0442, -0.0052],\n",
       "           [ 0.0483, -0.0098, -0.0104],\n",
       "           [ 0.0100, -0.0711, -0.0770]],\n",
       " \n",
       "          [[ 0.0538,  0.0838, -0.0246],\n",
       "           [ 0.0187, -0.0320, -0.0914],\n",
       "           [-0.0350,  0.0009,  0.0181]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0863,  0.0809, -0.0367],\n",
       "           [-0.0272, -0.0540, -0.0064],\n",
       "           [-0.0798,  0.0327,  0.0095]],\n",
       " \n",
       "          [[ 0.0069, -0.1286, -0.0161],\n",
       "           [ 0.0801, -0.0079, -0.0225],\n",
       "           [-0.0912, -0.0081, -0.0471]],\n",
       " \n",
       "          [[-0.0175,  0.1659,  0.0542],\n",
       "           [-0.0286,  0.0451,  0.0095],\n",
       "           [-0.0283, -0.0099,  0.0598]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0298,  0.0236,  0.0394],\n",
       "           [-0.0447, -0.0709, -0.0067],\n",
       "           [ 0.1815, -0.0220,  0.0530]],\n",
       " \n",
       "          [[-0.0778, -0.0085,  0.0602],\n",
       "           [-0.0714,  0.0257, -0.0096],\n",
       "           [ 0.0620,  0.0806, -0.0694]],\n",
       " \n",
       "          [[ 0.0337,  0.0188, -0.0276],\n",
       "           [-0.0437,  0.0488,  0.1091],\n",
       "           [ 0.0015,  0.0366, -0.0133]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-1.1631e-02, -1.0491e-01,  4.1975e-02],\n",
       "           [-7.1901e-02, -8.0612e-02, -8.2240e-03],\n",
       "           [-3.5556e-02, -1.4967e-02, -3.3037e-02]],\n",
       " \n",
       "          [[ 8.5557e-02,  1.8382e-02,  6.2513e-02],\n",
       "           [-5.3969e-02, -1.8421e-02, -8.3872e-03],\n",
       "           [-2.6213e-02, -3.8183e-02,  3.0050e-02]],\n",
       " \n",
       "          [[ 5.7538e-02,  8.8575e-02,  1.3295e-02],\n",
       "           [ 1.1051e-01,  2.0829e-02,  4.4348e-02],\n",
       "           [-3.9549e-02, -7.6052e-03, -7.3302e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.8531e-03, -5.6420e-02,  6.2892e-02],\n",
       "           [-2.4565e-02, -3.8822e-02, -4.9767e-02],\n",
       "           [-5.1525e-02, -4.1341e-02, -1.3354e-02]],\n",
       " \n",
       "          [[ 4.9256e-02,  1.1237e-01, -5.0065e-02],\n",
       "           [-2.8100e-02, -6.4485e-03, -8.3193e-02],\n",
       "           [ 1.8695e-02,  9.8891e-03, -1.1228e-01]],\n",
       " \n",
       "          [[-3.3884e-03,  3.9935e-02,  8.4446e-02],\n",
       "           [ 8.8831e-02, -7.7789e-02, -5.6826e-02],\n",
       "           [ 3.8143e-02,  6.7929e-02,  8.0893e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.4842e-02, -3.7018e-02, -2.0748e-02],\n",
       "           [-1.1705e-02, -1.0690e-01, -1.0241e-01],\n",
       "           [-5.6543e-02,  6.2558e-02,  7.7555e-02]],\n",
       " \n",
       "          [[-5.5692e-02, -9.9826e-02, -6.8577e-02],\n",
       "           [-2.6844e-04, -2.3029e-02, -5.9970e-02],\n",
       "           [-4.0435e-02,  6.9561e-02, -1.5144e-02]],\n",
       " \n",
       "          [[-2.8233e-02, -4.7436e-02, -5.4288e-02],\n",
       "           [-5.9471e-02,  1.3914e-02, -6.2775e-02],\n",
       "           [ 6.9503e-03, -5.2204e-02,  7.9657e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4686e-02,  3.7856e-02, -1.2033e-02],\n",
       "           [ 3.1264e-02,  5.4566e-02, -1.0090e-01],\n",
       "           [ 2.5385e-02,  4.4240e-02,  4.6601e-02]],\n",
       " \n",
       "          [[-7.1562e-02,  4.8779e-02, -2.1079e-02],\n",
       "           [ 7.4258e-02, -7.5843e-03, -1.1920e-01],\n",
       "           [ 4.1152e-02, -4.1534e-02,  1.2008e-01]],\n",
       " \n",
       "          [[-1.2368e-02,  1.5134e-02,  3.7792e-03],\n",
       "           [ 3.6228e-02,  6.7241e-02,  2.6904e-02],\n",
       "           [-4.0435e-02, -7.2946e-02, -1.5557e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.3852e-02,  1.6888e-02, -8.2863e-02],\n",
       "           [ 3.7668e-02, -3.5489e-02,  9.3071e-03],\n",
       "           [ 7.7484e-03, -1.5373e-02,  5.6817e-02]],\n",
       " \n",
       "          [[-2.2389e-02,  1.3824e-02,  7.1039e-03],\n",
       "           [-5.0719e-02,  3.2478e-02,  2.9572e-02],\n",
       "           [-1.4185e-01,  5.8931e-02,  3.7092e-02]],\n",
       " \n",
       "          [[-1.2023e-02,  7.1759e-02,  8.5572e-02],\n",
       "           [ 4.1405e-02, -6.2702e-03, -1.7477e-02],\n",
       "           [-1.0074e-01, -5.8724e-02, -3.0062e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.4060e-03, -2.7731e-02, -1.3594e-01],\n",
       "           [ 3.9199e-02, -8.8858e-02,  4.9091e-02],\n",
       "           [ 4.7126e-02,  1.1313e-01, -1.0937e-01]],\n",
       " \n",
       "          [[-4.4926e-02, -1.0042e-01, -3.8148e-02],\n",
       "           [ 5.2394e-02,  1.0352e-02, -1.0108e-03],\n",
       "           [ 5.3911e-02,  6.7592e-02,  9.0115e-02]],\n",
       " \n",
       "          [[-1.0203e-01, -5.1728e-02, -4.7407e-02],\n",
       "           [ 2.2111e-02, -6.1864e-02,  5.3628e-02],\n",
       "           [ 9.7889e-02,  4.0219e-02, -8.6833e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-8.0398e-02,  9.4246e-03, -3.8891e-02],\n",
       "           [ 2.2498e-02, -4.8985e-02, -2.5403e-02],\n",
       "           [-1.8288e-02,  4.8784e-02, -8.7771e-03]],\n",
       " \n",
       "          [[ 1.4230e-02, -1.3992e-01, -4.4348e-02],\n",
       "           [-1.1609e-01,  2.0026e-02, -4.0759e-02],\n",
       "           [ 4.3473e-02, -1.0305e-02,  9.7548e-02]],\n",
       " \n",
       "          [[-1.1464e-01, -1.6799e-02,  3.4758e-02],\n",
       "           [ 2.7415e-02,  9.6359e-02,  1.4933e-01],\n",
       "           [-9.1312e-02, -3.0102e-03,  7.1375e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-9.6123e-03, -2.4585e-02, -3.9506e-02],\n",
       "           [ 5.0802e-02,  3.9064e-02,  1.5980e-02],\n",
       "           [ 9.2384e-02,  7.5019e-02,  1.5153e-01]],\n",
       " \n",
       "          [[ 4.7361e-02, -1.9731e-02, -3.1004e-02],\n",
       "           [-1.7884e-02, -3.0734e-02,  4.7288e-02],\n",
       "           [ 2.4825e-02, -8.5187e-02, -4.7622e-02]],\n",
       " \n",
       "          [[ 5.2592e-02,  4.2989e-02,  6.8231e-02],\n",
       "           [ 4.4355e-02, -1.7168e-02,  6.5036e-02],\n",
       "           [-3.0349e-02, -5.4224e-02, -1.1760e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.7922e-02, -7.0732e-02,  2.7042e-03],\n",
       "           [-6.3263e-02,  4.5759e-03, -3.0682e-03],\n",
       "           [ 6.9787e-02,  9.2701e-02, -4.1813e-02]],\n",
       " \n",
       "          [[ 6.8385e-02, -1.7379e-02,  7.6357e-02],\n",
       "           [-1.4463e-02, -1.0971e-01,  1.8493e-03],\n",
       "           [ 2.5843e-02,  7.0059e-03,  4.8332e-02]],\n",
       " \n",
       "          [[ 7.7117e-02, -1.9617e-02, -5.3920e-02],\n",
       "           [ 1.9071e-02,  3.8248e-02,  8.8082e-02],\n",
       "           [-6.3939e-02,  3.7395e-02, -2.8542e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.4017e-02, -3.8738e-02,  7.8512e-02],\n",
       "           [-1.1582e-02,  5.9083e-03, -7.0087e-03],\n",
       "           [-3.6564e-02,  1.2914e-02, -2.6543e-02]],\n",
       " \n",
       "          [[-9.4790e-03, -1.4815e-02,  1.3458e-01],\n",
       "           [-8.0673e-02, -6.4833e-03, -1.8415e-02],\n",
       "           [ 2.4053e-02, -3.5505e-02, -1.1151e-01]],\n",
       " \n",
       "          [[-1.1051e-01, -8.2732e-02, -1.4148e-01],\n",
       "           [-3.5609e-02,  4.0469e-02,  7.6029e-02],\n",
       "           [ 2.4245e-02, -6.6577e-03, -8.2654e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.5353e-02,  6.2294e-02, -8.4803e-02],\n",
       "           [ 4.8087e-02, -5.7391e-02, -7.2652e-02],\n",
       "           [ 4.5508e-02, -2.4049e-02,  2.4240e-02]],\n",
       " \n",
       "          [[-6.1073e-02,  7.8768e-03, -2.1308e-02],\n",
       "           [ 4.6296e-02, -6.1005e-02, -7.4476e-02],\n",
       "           [-1.1848e-02,  1.4957e-01,  1.3666e-03]],\n",
       " \n",
       "          [[-2.1054e-02,  1.0429e-01, -8.6597e-03],\n",
       "           [-4.7403e-02, -3.0898e-02,  2.5248e-02],\n",
       "           [ 1.4204e-01, -4.5154e-02,  6.6886e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.3206e-02, -6.4906e-02,  8.8342e-02],\n",
       "           [ 3.4774e-02,  2.7763e-02,  9.2216e-03],\n",
       "           [-3.0793e-02,  4.0119e-02, -6.7724e-02]],\n",
       " \n",
       "          [[ 5.2713e-02, -8.1962e-03, -9.5749e-02],\n",
       "           [ 5.1346e-02,  2.1208e-02, -6.3860e-02],\n",
       "           [-8.0663e-03,  2.1211e-01,  1.2298e-02]],\n",
       " \n",
       "          [[-7.5577e-05,  5.4733e-02, -7.0262e-03],\n",
       "           [-3.2406e-02, -7.9848e-02,  4.3858e-02],\n",
       "           [-4.1217e-02,  6.9889e-02, -8.5907e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 1.0095e-01, -2.2684e-02, -2.5255e-02],\n",
       "           [-7.1816e-02, -6.3837e-03,  1.5364e-04],\n",
       "           [ 6.9949e-02, -5.1365e-02, -1.2750e-01]],\n",
       " \n",
       "          [[ 7.2128e-02,  2.2068e-02, -1.3317e-02],\n",
       "           [-5.5085e-02,  4.7483e-02,  4.0149e-02],\n",
       "           [ 1.1325e-01,  4.1647e-03,  6.8576e-02]],\n",
       " \n",
       "          [[ 3.4896e-02, -2.5551e-02,  1.5176e-02],\n",
       "           [ 6.4048e-02,  1.8714e-02, -3.4414e-02],\n",
       "           [-8.2848e-03,  9.9077e-03,  3.8927e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0433e-01,  5.7601e-02, -1.0413e-01],\n",
       "           [ 2.8217e-02, -1.5000e-02, -3.1526e-03],\n",
       "           [ 5.9223e-02, -3.3863e-02, -1.6835e-02]],\n",
       " \n",
       "          [[ 2.0069e-02,  9.2557e-03,  1.1245e-01],\n",
       "           [ 3.5339e-02,  2.9328e-02,  4.0261e-02],\n",
       "           [ 1.0363e-01, -8.4795e-02,  5.9390e-02]],\n",
       " \n",
       "          [[ 5.1285e-03, -2.3972e-02,  6.8685e-02],\n",
       "           [ 2.1042e-02, -2.9036e-02, -2.3156e-02],\n",
       "           [-7.7512e-02, -2.3958e-03,  2.4265e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.3075e-02, -6.7076e-02,  4.4246e-02],\n",
       "           [ 4.4796e-03, -8.2404e-02, -4.6928e-02],\n",
       "           [ 1.4843e-01,  1.1974e-01,  1.0048e-01]],\n",
       " \n",
       "          [[-7.5112e-02,  5.6924e-02, -4.1416e-02],\n",
       "           [-3.9686e-02, -3.4373e-02, -4.6195e-02],\n",
       "           [-2.6493e-02, -3.1447e-02, -1.0933e-01]],\n",
       " \n",
       "          [[ 3.7062e-02, -8.4818e-03, -6.9524e-02],\n",
       "           [-1.2671e-01, -8.4538e-02,  2.9052e-02],\n",
       "           [ 2.6257e-03,  3.7787e-02,  2.0881e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.3099e-02,  6.6828e-03, -3.1283e-02],\n",
       "           [ 4.9244e-02, -1.2255e-01,  5.1473e-03],\n",
       "           [-2.5709e-02,  5.2088e-02, -1.8865e-02]],\n",
       " \n",
       "          [[-2.2971e-02,  5.5300e-02, -2.1062e-02],\n",
       "           [-4.5078e-02,  3.3220e-03, -3.2185e-02],\n",
       "           [-4.0979e-02, -9.1198e-02,  9.4908e-02]],\n",
       " \n",
       "          [[-3.6587e-02,  1.2190e-02,  1.5322e-01],\n",
       "           [-3.0646e-02,  2.6227e-02, -2.7832e-02],\n",
       "           [ 2.9771e-02,  6.7630e-02,  8.2739e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 7.3350e-02,  5.8348e-02,  2.6970e-02],\n",
       "           [ 6.6075e-02,  2.4797e-02, -5.9663e-05],\n",
       "           [-2.0162e-02, -1.4814e-03,  7.7719e-03]],\n",
       " \n",
       "          [[-3.2940e-02, -3.9875e-02, -1.4459e-02],\n",
       "           [-4.2460e-02,  2.0116e-03,  1.2728e-02],\n",
       "           [ 9.2337e-02,  8.3528e-02,  4.6485e-02]],\n",
       " \n",
       "          [[-8.0646e-02, -9.5482e-02, -3.2994e-02],\n",
       "           [ 3.7230e-02, -1.9535e-03,  3.0590e-02],\n",
       "           [ 5.3471e-03, -9.1722e-02, -5.3454e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.2880e-02,  8.5484e-02,  2.5730e-02],\n",
       "           [ 1.0274e-03, -3.9728e-02, -2.0347e-01],\n",
       "           [ 1.1004e-01, -4.8907e-02, -9.1623e-02]],\n",
       " \n",
       "          [[-8.6201e-02,  4.6550e-02,  8.4650e-02],\n",
       "           [-5.3679e-03,  3.9323e-02,  3.1789e-02],\n",
       "           [-2.1341e-02, -2.9781e-03, -8.4381e-02]],\n",
       " \n",
       "          [[ 1.2176e-01,  1.5685e-03,  1.4443e-01],\n",
       "           [-1.8069e-02, -5.4298e-02, -3.2337e-02],\n",
       "           [ 4.2298e-02, -2.1023e-02,  1.2368e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.3332e-02,  6.8650e-02, -5.1050e-02],\n",
       "           [ 2.8294e-02, -5.4814e-02,  7.0822e-03],\n",
       "           [-3.0169e-02, -4.4563e-02, -3.7325e-02]],\n",
       " \n",
       "          [[-3.5269e-02,  7.5333e-02,  7.7381e-02],\n",
       "           [ 8.7155e-02,  1.2148e-01, -1.3071e-01],\n",
       "           [ 9.9139e-02,  5.6877e-02,  7.5974e-02]],\n",
       " \n",
       "          [[-6.8818e-02,  4.1637e-02,  8.8349e-02],\n",
       "           [-6.5768e-03, -5.6006e-02,  3.2285e-02],\n",
       "           [-7.9384e-02, -3.6785e-02, -1.5809e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.5481e-02, -7.3216e-02,  9.7985e-02],\n",
       "           [-5.3073e-02,  2.3229e-02, -7.3709e-02],\n",
       "           [ 3.1829e-02,  3.0157e-02,  1.1285e-02]],\n",
       " \n",
       "          [[ 8.4028e-03, -6.8298e-03,  1.9518e-02],\n",
       "           [ 4.0497e-02, -5.9827e-02, -2.8483e-02],\n",
       "           [-2.5854e-03,  2.1493e-02,  9.6537e-02]],\n",
       " \n",
       "          [[-6.9650e-02, -2.6071e-02, -5.7901e-02],\n",
       "           [ 4.1636e-02, -2.9873e-02, -8.9100e-02],\n",
       "           [ 2.7598e-02, -2.8123e-03,  3.2969e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.2744e-02,  6.9474e-02,  5.1365e-02],\n",
       "           [-1.8065e-02,  1.2109e-01,  2.6814e-02],\n",
       "           [ 1.7159e-03, -1.1821e-01,  4.7830e-02]],\n",
       " \n",
       "          [[-4.3690e-03, -1.5107e-02, -1.2003e-02],\n",
       "           [-2.9603e-02,  5.8615e-02, -7.0276e-02],\n",
       "           [-1.1302e-02,  5.0610e-02,  1.4479e-02]],\n",
       " \n",
       "          [[ 1.4216e-02, -1.1063e-01, -3.9805e-02],\n",
       "           [ 1.0322e-04, -7.1320e-02,  2.4615e-02],\n",
       "           [-9.4114e-02, -3.8773e-02, -6.4017e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.0229e-02, -4.8311e-02, -3.7319e-02],\n",
       "           [-1.8318e-02, -4.2137e-02, -5.6018e-02],\n",
       "           [-6.1513e-03, -9.0295e-02, -9.5744e-02]],\n",
       " \n",
       "          [[ 5.9318e-02,  2.4430e-02, -3.0770e-02],\n",
       "           [-5.0550e-02, -3.3418e-02, -1.3602e-02],\n",
       "           [-6.0871e-02, -1.2093e-01, -3.7933e-02]],\n",
       " \n",
       "          [[ 1.3963e-02,  2.9894e-02,  4.0262e-02],\n",
       "           [ 3.1602e-02,  9.8601e-03,  7.5029e-02],\n",
       "           [ 3.9321e-02,  1.5482e-02,  4.9133e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.0155e-02, -3.0973e-02,  2.7505e-02],\n",
       "           [ 3.5022e-02,  3.3123e-02,  3.3898e-02],\n",
       "           [-2.1047e-02, -2.9693e-02,  2.7318e-02]],\n",
       " \n",
       "          [[ 5.1401e-02,  2.5689e-02,  9.8427e-04],\n",
       "           [-2.1050e-02, -2.9694e-02, -2.3320e-02],\n",
       "           [-9.0241e-03, -1.0919e-01,  7.8859e-02]],\n",
       " \n",
       "          [[-1.3757e-02, -5.2087e-03, -6.6674e-02],\n",
       "           [ 3.2318e-02, -2.7648e-02, -1.3501e-01],\n",
       "           [-2.3880e-03,  9.0680e-02,  1.1552e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.6479e-02,  7.3650e-03, -9.0228e-02],\n",
       "           [ 2.7577e-02, -4.2580e-02,  3.0245e-03],\n",
       "           [-5.1706e-02,  3.5496e-02, -4.7522e-02]],\n",
       " \n",
       "          [[-9.7391e-02,  3.8558e-02, -1.0219e-01],\n",
       "           [ 7.9684e-03, -1.2262e-02, -5.6458e-02],\n",
       "           [ 4.2327e-02,  7.1489e-03, -4.4973e-02]],\n",
       " \n",
       "          [[-3.1967e-02, -3.2877e-02, -8.5862e-02],\n",
       "           [ 7.7273e-02,  8.2008e-02, -2.5105e-02],\n",
       "           [-7.5887e-02,  9.2175e-02,  1.1438e-03]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-7.5296e-03, -5.3868e-02, -4.1403e-02],\n",
       "           [ 2.5041e-02, -2.3262e-02, -2.6508e-03],\n",
       "           [-9.3994e-03,  6.3009e-02,  4.8513e-02]],\n",
       " \n",
       "          [[-9.3279e-02,  1.0884e-02, -1.6075e-02],\n",
       "           [ 2.9342e-02, -5.6213e-03,  2.7032e-02],\n",
       "           [-1.4250e-02, -8.8358e-03,  3.6041e-03]],\n",
       " \n",
       "          [[-2.5883e-02,  3.1272e-03, -1.6449e-02],\n",
       "           [-1.9450e-02, -5.9722e-02, -6.4374e-02],\n",
       "           [ 5.7171e-02,  5.1784e-02,  9.5043e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.4884e-02, -4.5541e-02, -2.1755e-02],\n",
       "           [ 4.3789e-02,  3.2287e-02,  6.5476e-02],\n",
       "           [-2.9865e-02, -5.1130e-02,  2.6286e-05]],\n",
       " \n",
       "          [[-9.0173e-02,  5.9496e-03, -6.9023e-02],\n",
       "           [-5.6939e-02, -5.1061e-03, -6.6074e-02],\n",
       "           [-6.9495e-02, -3.7345e-02,  5.3278e-02]],\n",
       " \n",
       "          [[ 2.2953e-03, -3.8881e-02, -1.9174e-02],\n",
       "           [ 4.1184e-02,  2.2265e-03,  3.4940e-03],\n",
       "           [-2.9652e-02, -3.5502e-02,  2.4571e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.4910e-02, -9.3232e-02, -8.0746e-02],\n",
       "           [-6.0487e-02,  4.1857e-03, -1.5362e-02],\n",
       "           [ 6.0200e-02, -3.2021e-02, -6.7838e-03]],\n",
       " \n",
       "          [[ 9.9289e-03, -2.4831e-02,  3.2403e-02],\n",
       "           [ 7.2485e-03, -7.1025e-02, -2.0238e-02],\n",
       "           [-5.0650e-02, -2.2089e-03, -3.9155e-02]],\n",
       " \n",
       "          [[-3.6342e-02,  4.9792e-02, -4.2345e-03],\n",
       "           [ 2.9861e-03,  7.6006e-02, -1.2940e-02],\n",
       "           [ 4.3428e-03,  2.1159e-02, -5.6371e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6114e-02,  2.4905e-03, -1.1955e-02],\n",
       "           [-2.0665e-02, -4.0275e-02, -6.8287e-02],\n",
       "           [-7.7514e-02,  6.6288e-03,  6.0383e-02]],\n",
       " \n",
       "          [[-1.8212e-02, -6.3552e-02, -4.1952e-03],\n",
       "           [-5.4808e-02, -2.3915e-02,  1.3923e-02],\n",
       "           [ 6.0099e-02, -1.3352e-01,  6.9585e-02]],\n",
       " \n",
       "          [[-7.5850e-04, -2.2372e-02,  4.5773e-02],\n",
       "           [-2.5647e-02, -1.1845e-03,  4.7292e-04],\n",
       "           [-1.7448e-02, -8.6969e-02,  1.5692e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8630e-02, -7.4399e-02, -4.9979e-02],\n",
       "           [-1.5131e-02,  5.2373e-02,  4.4816e-02],\n",
       "           [ 1.9037e-03, -7.0673e-02,  2.0991e-03]],\n",
       " \n",
       "          [[ 9.7674e-02,  2.1907e-02,  3.4393e-02],\n",
       "           [ 1.5399e-02, -1.1062e-02, -2.2711e-02],\n",
       "           [ 7.8898e-03,  4.8898e-02, -1.3750e-02]],\n",
       " \n",
       "          [[-4.3271e-02, -1.3632e-02,  4.7926e-02],\n",
       "           [-1.7469e-03, -1.1332e-02,  5.4961e-02],\n",
       "           [-7.2030e-02, -6.7335e-02,  2.5207e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.0352e-02, -4.6609e-02,  7.8340e-02],\n",
       "           [-3.1309e-02,  5.3794e-02,  3.4928e-02],\n",
       "           [ 1.3577e-02,  2.1876e-02, -4.1797e-02]],\n",
       " \n",
       "          [[ 1.1315e-02, -1.6968e-02, -6.3624e-02],\n",
       "           [-1.6803e-02, -4.2382e-03, -4.0892e-02],\n",
       "           [ 5.4499e-02,  2.1522e-02,  1.2536e-02]],\n",
       " \n",
       "          [[-4.6562e-03, -6.9226e-02,  4.3666e-02],\n",
       "           [-2.3221e-02,  8.6473e-03, -2.8669e-02],\n",
       "           [-2.1207e-02,  4.3084e-02,  2.7222e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 4.0486e-02,  5.3406e-02, -4.2440e-03],\n",
       "           [ 1.3366e-03,  5.0104e-02,  2.3591e-02],\n",
       "           [-4.5866e-02, -3.1130e-02, -2.9717e-02]],\n",
       " \n",
       "          [[-3.5099e-02,  3.6053e-02,  1.1016e-02],\n",
       "           [ 4.1388e-03, -1.7148e-02, -6.5652e-02],\n",
       "           [-2.5983e-02, -8.3176e-03, -1.7776e-02]],\n",
       " \n",
       "          [[-2.9922e-02,  6.6753e-04, -5.9734e-02],\n",
       "           [-7.2006e-03, -6.7081e-02, -5.1718e-02],\n",
       "           [-2.0971e-02, -4.2827e-02, -5.0483e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.4160e-02,  4.1434e-02, -4.4698e-02],\n",
       "           [ 1.7171e-02,  2.5852e-02, -2.9218e-02],\n",
       "           [ 4.8476e-02, -3.1161e-04,  3.7053e-02]],\n",
       " \n",
       "          [[-2.0222e-02, -6.7817e-03, -3.0730e-02],\n",
       "           [ 6.2184e-02,  1.3383e-02, -3.0575e-03],\n",
       "           [-3.3400e-02, -6.0657e-03, -1.6462e-02]],\n",
       " \n",
       "          [[-3.8082e-02,  7.2240e-02,  5.3336e-02],\n",
       "           [-7.6425e-02, -6.1911e-02,  3.4676e-02],\n",
       "           [-1.0075e-01,  6.5042e-03,  2.4582e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.3035e-03,  4.0479e-02, -2.1696e-02],\n",
       "           [-5.1551e-02,  6.2238e-03,  8.2940e-03],\n",
       "           [ 3.1804e-02, -4.9351e-02,  3.2121e-02]],\n",
       " \n",
       "          [[-5.5757e-02, -9.0812e-02, -3.3091e-02],\n",
       "           [-4.1386e-02,  5.4172e-02,  1.1443e-02],\n",
       "           [ 1.2799e-02,  2.5390e-02,  1.7725e-02]],\n",
       " \n",
       "          [[-9.1454e-03,  2.3888e-02,  9.1238e-03],\n",
       "           [ 8.1150e-02, -5.5110e-02,  3.4098e-02],\n",
       "           [-9.8163e-03,  5.6325e-02,  2.6109e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.1055e-03,  7.2655e-02, -2.1073e-03],\n",
       "           [-7.0024e-02,  8.6384e-02,  8.3271e-03],\n",
       "           [ 3.8158e-02,  8.0204e-03, -6.9287e-03]],\n",
       " \n",
       "          [[ 3.1346e-02, -6.3892e-02,  1.1210e-01],\n",
       "           [-7.7962e-02,  1.7374e-02, -5.8917e-02],\n",
       "           [-2.9423e-02, -8.6305e-02, -1.9374e-03]],\n",
       " \n",
       "          [[-1.5501e-02, -3.9837e-02, -9.1206e-03],\n",
       "           [ 1.9458e-02, -2.6238e-02, -1.8305e-02],\n",
       "           [ 7.8515e-02,  5.5093e-02,  1.3555e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.9568e-02, -3.1791e-02,  6.5458e-03],\n",
       "           [-4.8919e-02, -1.0670e-02, -7.9426e-02],\n",
       "           [-3.3251e-02,  3.0665e-02, -1.6404e-02]],\n",
       " \n",
       "          [[-1.1110e-02,  2.8084e-02,  3.2300e-02],\n",
       "           [-5.8566e-02, -6.0130e-02,  6.2629e-02],\n",
       "           [-1.4200e-02, -1.4830e-02, -3.3551e-03]],\n",
       " \n",
       "          [[-4.0563e-02,  3.4859e-02, -1.0755e-02],\n",
       "           [-5.2343e-02,  5.3347e-02,  1.0555e-02],\n",
       "           [-1.1656e-02,  1.4679e-02, -3.8478e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0035e-01,  4.2260e-02, -4.2222e-03],\n",
       "           [-4.5199e-02,  3.8393e-03, -4.4814e-03],\n",
       "           [ 4.2303e-02,  5.7139e-02,  6.4237e-03]],\n",
       " \n",
       "          [[ 8.4828e-02, -3.2823e-02, -5.5130e-02],\n",
       "           [-6.9816e-02,  7.0317e-02,  5.0324e-02],\n",
       "           [ 9.4747e-03,  5.3104e-02, -4.9606e-02]],\n",
       " \n",
       "          [[ 6.2054e-04,  3.0193e-02, -4.5139e-02],\n",
       "           [ 2.9166e-02,  1.0739e-02, -5.5100e-02],\n",
       "           [-7.3845e-02,  1.7077e-02,  2.0839e-03]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-1.5654e-02, -7.0718e-02, -2.7808e-03],\n",
       "           [-2.6882e-02,  7.7569e-03, -5.5501e-03],\n",
       "           [ 1.4871e-02,  2.8239e-02,  2.0740e-02]],\n",
       " \n",
       "          [[ 3.0123e-02, -1.5210e-03, -3.2223e-02],\n",
       "           [-3.0444e-02,  3.9874e-02,  9.1515e-03],\n",
       "           [ 2.2116e-02, -3.0723e-02, -1.4318e-02]],\n",
       " \n",
       "          [[-1.6883e-02,  3.2236e-02,  2.4843e-02],\n",
       "           [ 4.6261e-02, -2.7652e-02, -3.9491e-02],\n",
       "           [ 7.5484e-02,  1.7323e-02,  2.8359e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.6542e-02, -1.7649e-02,  1.5999e-02],\n",
       "           [ 3.9952e-02, -1.0300e-03, -7.4450e-02],\n",
       "           [ 1.2368e-02,  7.4395e-02,  1.5465e-02]],\n",
       " \n",
       "          [[ 4.5884e-03,  9.2556e-03,  1.6442e-02],\n",
       "           [ 2.3965e-02, -8.1653e-03, -7.5481e-03],\n",
       "           [ 2.5584e-03,  2.2263e-02, -2.9121e-02]],\n",
       " \n",
       "          [[ 3.1536e-02, -1.1466e-02,  1.2662e-03],\n",
       "           [-6.0060e-02,  2.1428e-02, -1.0769e-02],\n",
       "           [ 6.8064e-02, -5.6414e-02, -7.2010e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.0792e-02,  7.9507e-03, -6.9861e-02],\n",
       "           [-4.6099e-03, -2.9273e-02,  1.8228e-02],\n",
       "           [ 8.6912e-03,  4.7557e-04, -8.6624e-03]],\n",
       " \n",
       "          [[ 8.1313e-02,  1.0119e-02, -2.9666e-02],\n",
       "           [-3.1981e-02,  1.0471e-02,  7.4801e-02],\n",
       "           [-3.6416e-02,  6.5300e-02, -1.9494e-02]],\n",
       " \n",
       "          [[ 1.7614e-02, -3.0554e-02,  7.5564e-03],\n",
       "           [-4.9084e-03,  6.3349e-02,  2.4506e-02],\n",
       "           [ 4.6170e-02,  2.5637e-02, -9.5370e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.7551e-03,  2.3664e-02,  2.6437e-02],\n",
       "           [ 4.8216e-03,  2.2458e-02, -1.9475e-02],\n",
       "           [ 1.6678e-02,  1.6030e-02,  4.8118e-02]],\n",
       " \n",
       "          [[-4.9040e-02,  1.8099e-02,  2.4711e-02],\n",
       "           [ 1.0580e-01,  2.3306e-02,  5.9706e-02],\n",
       "           [ 3.7593e-02, -3.9243e-02,  7.0643e-03]],\n",
       " \n",
       "          [[-6.6045e-02, -4.0301e-02, -2.2330e-02],\n",
       "           [-4.3910e-02, -1.7769e-02, -5.3929e-03],\n",
       "           [-1.2256e-02, -4.9693e-02,  1.7644e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.6763e-02, -3.8812e-02, -1.3974e-02],\n",
       "           [ 6.2501e-02, -4.7372e-02, -8.4936e-03],\n",
       "           [-5.1848e-02, -2.9499e-02,  1.1886e-02]],\n",
       " \n",
       "          [[ 2.5638e-02, -5.6383e-02,  5.0465e-02],\n",
       "           [-1.7903e-03,  2.7978e-03,  5.2448e-02],\n",
       "           [-1.9455e-03, -2.2447e-02,  6.9066e-03]],\n",
       " \n",
       "          [[-5.9541e-03, -6.4388e-02, -8.2634e-02],\n",
       "           [-4.3798e-02,  1.4821e-02,  1.3011e-02],\n",
       "           [-1.8794e-02,  6.4792e-02,  2.3171e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.3578e-02,  1.5224e-02,  1.6003e-02],\n",
       "           [-6.4440e-02, -3.5940e-02,  7.8589e-02],\n",
       "           [-7.0404e-02,  1.0251e-03,  5.4530e-03]],\n",
       " \n",
       "          [[ 1.8298e-02, -8.2163e-03, -5.1831e-02],\n",
       "           [ 4.6742e-02,  4.0297e-02, -2.4433e-02],\n",
       "           [-1.1559e-01, -7.2547e-02,  1.9521e-03]],\n",
       " \n",
       "          [[ 3.8405e-02,  9.6385e-04, -2.0617e-03],\n",
       "           [-1.6812e-02, -3.9271e-02, -4.3501e-02],\n",
       "           [-1.1097e-02, -2.0903e-02, -6.4387e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.3540e-02, -4.8829e-02,  2.6865e-03],\n",
       "           [-3.2132e-02,  6.0494e-02,  5.0573e-02],\n",
       "           [-2.0716e-02, -3.1338e-02,  3.2602e-02]],\n",
       " \n",
       "          [[-2.0211e-02,  2.6381e-02,  4.7288e-02],\n",
       "           [-3.5187e-02, -4.1253e-02, -6.7214e-02],\n",
       "           [ 1.1378e-02,  1.0036e-02, -1.3828e-03]],\n",
       " \n",
       "          [[ 3.8139e-02, -4.1394e-02,  9.4668e-03],\n",
       "           [ 3.2398e-02,  1.9262e-02,  3.7320e-03],\n",
       "           [ 2.6759e-03, -6.0278e-04,  1.9786e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.3053e-02,  1.9210e-02,  9.2916e-03],\n",
       "           [-1.0816e-01, -5.7024e-02,  3.6387e-02],\n",
       "           [ 6.0222e-02,  9.7002e-02,  1.5483e-02]],\n",
       " \n",
       "          [[-2.3369e-02,  1.8667e-02,  2.4758e-03],\n",
       "           [ 4.9937e-02,  4.5532e-02, -5.5256e-03],\n",
       "           [-7.2339e-02, -2.8222e-02,  1.9098e-02]],\n",
       " \n",
       "          [[-1.9508e-02,  1.3318e-02,  1.0157e-02],\n",
       "           [ 7.4991e-02, -9.7810e-03,  4.1938e-02],\n",
       "           [ 2.1986e-02, -3.7224e-02, -1.7688e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.8082e-02, -4.9494e-02, -7.2122e-02],\n",
       "           [-2.9396e-02, -6.1578e-02,  5.0320e-02],\n",
       "           [-2.2474e-02,  1.1633e-02, -5.8891e-03]],\n",
       " \n",
       "          [[-1.9910e-02, -3.3917e-02,  3.0784e-02],\n",
       "           [ 1.0234e-01, -1.1938e-02,  1.3209e-02],\n",
       "           [ 3.8799e-02,  2.4449e-03, -4.3719e-02]],\n",
       " \n",
       "          [[ 5.6337e-02,  4.8725e-02, -7.8409e-02],\n",
       "           [-3.3066e-02,  1.8687e-02,  2.4384e-02],\n",
       "           [-5.0271e-03,  5.1880e-02,  6.7136e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4102e-02,  6.8952e-02,  1.0948e-02],\n",
       "           [-5.7867e-02, -2.5733e-02, -1.3818e-02],\n",
       "           [ 2.3509e-03, -2.3926e-02, -2.9158e-02]],\n",
       " \n",
       "          [[ 9.6689e-02,  2.9886e-02,  2.7677e-02],\n",
       "           [-3.7595e-03,  2.7944e-02,  4.7245e-03],\n",
       "           [-1.0312e-01, -4.6712e-02, -1.2268e-02]],\n",
       " \n",
       "          [[-6.5448e-02,  5.5441e-03, -4.0430e-02],\n",
       "           [-2.9044e-02,  8.0829e-03,  4.2968e-02],\n",
       "           [-2.7089e-05, -2.9255e-02, -7.9101e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.5189e-02, -3.7248e-02, -4.4804e-02],\n",
       "           [-3.7937e-02,  2.1363e-02, -5.1712e-02],\n",
       "           [-3.3885e-02,  1.5180e-02,  5.6410e-02]],\n",
       " \n",
       "          [[-1.6899e-03,  7.7165e-02, -4.4315e-02],\n",
       "           [-7.0221e-02, -6.5723e-02,  6.9656e-03],\n",
       "           [-6.4324e-02, -5.4534e-03, -1.4747e-02]],\n",
       " \n",
       "          [[-7.9786e-03, -4.6012e-03,  1.0949e-02],\n",
       "           [-4.0660e-02,  4.1619e-02,  2.2801e-02],\n",
       "           [-1.0244e-02,  3.0205e-02, -6.4227e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.6499e-02, -1.1140e-02, -5.9629e-03],\n",
       "           [-2.2556e-02,  5.5370e-02,  2.1512e-02],\n",
       "           [ 3.2327e-02, -6.9942e-02,  9.0923e-03]],\n",
       " \n",
       "          [[-6.6531e-03,  1.8287e-02,  6.8828e-03],\n",
       "           [ 4.1759e-03, -5.1271e-02,  1.8888e-02],\n",
       "           [-2.3875e-02, -1.8017e-02, -5.2034e-02]],\n",
       " \n",
       "          [[-1.9510e-02, -5.7550e-03,  7.2974e-02],\n",
       "           [ 1.2425e-02,  4.8999e-02, -3.0569e-02],\n",
       "           [ 1.3166e-02, -5.2720e-03, -1.6111e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0258]],\n",
       " \n",
       "          [[-0.0294]],\n",
       " \n",
       "          [[ 0.1631]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0023]],\n",
       " \n",
       "          [[-0.0666]],\n",
       " \n",
       "          [[-0.0969]]],\n",
       " \n",
       " \n",
       "         [[[-0.2974]],\n",
       " \n",
       "          [[ 0.0550]],\n",
       " \n",
       "          [[-0.1465]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1781]],\n",
       " \n",
       "          [[-0.2020]],\n",
       " \n",
       "          [[-0.0367]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1883]],\n",
       " \n",
       "          [[ 0.0654]],\n",
       " \n",
       "          [[ 0.1151]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.3095]],\n",
       " \n",
       "          [[ 0.0356]],\n",
       " \n",
       "          [[ 0.1692]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.1788]],\n",
       " \n",
       "          [[ 0.2476]],\n",
       " \n",
       "          [[ 0.0138]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0338]],\n",
       " \n",
       "          [[ 0.0911]],\n",
       " \n",
       "          [[ 0.0865]]],\n",
       " \n",
       " \n",
       "         [[[-0.0536]],\n",
       " \n",
       "          [[-0.0105]],\n",
       " \n",
       "          [[ 0.1035]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0345]],\n",
       " \n",
       "          [[ 0.0120]],\n",
       " \n",
       "          [[ 0.0470]]],\n",
       " \n",
       " \n",
       "         [[[-0.0319]],\n",
       " \n",
       "          [[-0.0205]],\n",
       " \n",
       "          [[ 0.1767]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1622]],\n",
       " \n",
       "          [[ 0.0568]],\n",
       " \n",
       "          [[ 0.0128]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0327, -0.0452, -0.0400],\n",
       "           [-0.0174, -0.0334,  0.0384],\n",
       "           [ 0.0315,  0.0624,  0.0209]],\n",
       " \n",
       "          [[ 0.0155,  0.0675, -0.0377],\n",
       "           [ 0.0164,  0.0821,  0.0702],\n",
       "           [-0.0217,  0.0173, -0.0757]],\n",
       " \n",
       "          [[-0.0009,  0.0339, -0.0599],\n",
       "           [ 0.0173,  0.0033,  0.0768],\n",
       "           [ 0.0960, -0.0724,  0.0511]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0294, -0.0168, -0.0274],\n",
       "           [ 0.0307,  0.0075, -0.0338],\n",
       "           [ 0.0208,  0.0571,  0.0098]],\n",
       " \n",
       "          [[ 0.0089,  0.0347, -0.0527],\n",
       "           [ 0.0180, -0.0627,  0.0786],\n",
       "           [-0.0695,  0.0033, -0.0548]],\n",
       " \n",
       "          [[ 0.0257, -0.0190,  0.0135],\n",
       "           [-0.0668,  0.0027, -0.0220],\n",
       "           [ 0.0028, -0.0572, -0.0631]]],\n",
       " \n",
       " \n",
       "         [[[-0.0182,  0.0047,  0.0278],\n",
       "           [ 0.0466, -0.0612, -0.0388],\n",
       "           [ 0.0456, -0.0051,  0.0496]],\n",
       " \n",
       "          [[ 0.0029,  0.0542,  0.0204],\n",
       "           [ 0.0115,  0.0074,  0.0060],\n",
       "           [ 0.1381,  0.0374,  0.0596]],\n",
       " \n",
       "          [[-0.0747,  0.0354,  0.0980],\n",
       "           [-0.0729,  0.0007,  0.0093],\n",
       "           [ 0.0149,  0.0322, -0.0998]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0488, -0.0432, -0.0356],\n",
       "           [-0.0500, -0.0145,  0.0992],\n",
       "           [ 0.0085,  0.0215, -0.0088]],\n",
       " \n",
       "          [[ 0.0129, -0.0202, -0.0319],\n",
       "           [ 0.0596,  0.0206, -0.0085],\n",
       "           [-0.0093,  0.0550,  0.0261]],\n",
       " \n",
       "          [[ 0.0245,  0.0625,  0.0711],\n",
       "           [ 0.0171, -0.0140, -0.0043],\n",
       "           [-0.0240,  0.0435, -0.0139]]],\n",
       " \n",
       " \n",
       "         [[[-0.0362,  0.0515,  0.0076],\n",
       "           [ 0.0083,  0.0074,  0.0602],\n",
       "           [-0.0171, -0.0180,  0.0180]],\n",
       " \n",
       "          [[-0.0350,  0.0148,  0.0072],\n",
       "           [-0.0110, -0.0056,  0.0008],\n",
       "           [-0.0627, -0.0146, -0.0366]],\n",
       " \n",
       "          [[-0.0157,  0.0706,  0.0105],\n",
       "           [-0.0896,  0.0538, -0.0561],\n",
       "           [ 0.0110,  0.0579,  0.0350]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0006, -0.0515, -0.0714],\n",
       "           [-0.0212,  0.0155,  0.0451],\n",
       "           [-0.0315,  0.0349, -0.0902]],\n",
       " \n",
       "          [[-0.0515, -0.0095,  0.0072],\n",
       "           [ 0.0489,  0.0516, -0.0007],\n",
       "           [-0.0007, -0.0219,  0.0108]],\n",
       " \n",
       "          [[ 0.0253, -0.0117,  0.0337],\n",
       "           [ 0.0059,  0.0475,  0.0042],\n",
       "           [-0.0322,  0.0277, -0.0440]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0274,  0.0472,  0.0182],\n",
       "           [-0.0358,  0.0827, -0.0171],\n",
       "           [-0.0172, -0.0203, -0.0054]],\n",
       " \n",
       "          [[ 0.0165,  0.0318, -0.0580],\n",
       "           [ 0.1127, -0.0083, -0.0712],\n",
       "           [-0.1318, -0.0308,  0.0372]],\n",
       " \n",
       "          [[ 0.0521,  0.0310, -0.0161],\n",
       "           [ 0.0269,  0.0717,  0.0021],\n",
       "           [-0.0603,  0.0122,  0.1028]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0192,  0.0035,  0.0254],\n",
       "           [-0.0281, -0.0192,  0.0229],\n",
       "           [ 0.0013,  0.0286, -0.0305]],\n",
       " \n",
       "          [[-0.0114,  0.0008, -0.0125],\n",
       "           [ 0.0462,  0.0223,  0.0212],\n",
       "           [-0.0268, -0.0005, -0.0811]],\n",
       " \n",
       "          [[-0.0427, -0.0599,  0.0109],\n",
       "           [ 0.0401,  0.0527, -0.0234],\n",
       "           [-0.0447, -0.0099, -0.0049]]],\n",
       " \n",
       " \n",
       "         [[[-0.0421, -0.0235,  0.0645],\n",
       "           [-0.0463, -0.0112, -0.0137],\n",
       "           [-0.0124,  0.1115,  0.0309]],\n",
       " \n",
       "          [[ 0.0476,  0.0222, -0.0557],\n",
       "           [ 0.0136, -0.0671,  0.1021],\n",
       "           [ 0.0828,  0.0055, -0.0162]],\n",
       " \n",
       "          [[-0.0836,  0.0021, -0.0024],\n",
       "           [-0.0336,  0.0020,  0.0361],\n",
       "           [-0.0376,  0.0629,  0.0295]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0288, -0.0453,  0.0415],\n",
       "           [ 0.0734, -0.0710,  0.0107],\n",
       "           [ 0.0198, -0.0581,  0.0193]],\n",
       " \n",
       "          [[-0.0294,  0.0472,  0.0567],\n",
       "           [ 0.0173, -0.0194,  0.0025],\n",
       "           [ 0.0265, -0.0240, -0.0288]],\n",
       " \n",
       "          [[-0.0167,  0.0498,  0.0466],\n",
       "           [ 0.0213, -0.0043,  0.0248],\n",
       "           [-0.0133, -0.0966, -0.0250]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0259,  0.0738, -0.0164],\n",
       "           [ 0.0563,  0.0305,  0.0488],\n",
       "           [ 0.0049,  0.0320,  0.0483]],\n",
       " \n",
       "          [[ 0.0370,  0.0162,  0.0328],\n",
       "           [ 0.0452,  0.0200,  0.0326],\n",
       "           [-0.0239, -0.0358,  0.0342]],\n",
       " \n",
       "          [[-0.0676,  0.0648,  0.0019],\n",
       "           [ 0.0105, -0.0333,  0.0327],\n",
       "           [ 0.0170, -0.0383,  0.0188]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0198, -0.0866, -0.0046],\n",
       "           [-0.0395, -0.0011, -0.0541],\n",
       "           [-0.0495,  0.0450, -0.0576]],\n",
       " \n",
       "          [[-0.0186, -0.0583,  0.0173],\n",
       "           [-0.0399,  0.0646, -0.0381],\n",
       "           [-0.0728, -0.0327, -0.0182]],\n",
       " \n",
       "          [[-0.0153,  0.0624,  0.0190],\n",
       "           [ 0.0334,  0.0439,  0.0195],\n",
       "           [ 0.0709,  0.0309,  0.0095]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0472, -0.0280, -0.0331],\n",
       "           [ 0.0246, -0.0062, -0.0070],\n",
       "           [ 0.0327, -0.0715,  0.0002]],\n",
       " \n",
       "          [[-0.0405,  0.0909,  0.0589],\n",
       "           [ 0.0080,  0.0630, -0.0489],\n",
       "           [-0.0154,  0.0287, -0.0031]],\n",
       " \n",
       "          [[ 0.0404, -0.0221,  0.0072],\n",
       "           [-0.0591, -0.0363, -0.0184],\n",
       "           [-0.0210,  0.0286,  0.0761]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0448, -0.0051,  0.0190],\n",
       "           [-0.0940,  0.0548,  0.0128],\n",
       "           [ 0.0880, -0.0128, -0.0143]],\n",
       " \n",
       "          [[-0.0310, -0.0846,  0.0349],\n",
       "           [-0.0259,  0.0102, -0.0418],\n",
       "           [-0.0431, -0.0434,  0.0152]],\n",
       " \n",
       "          [[ 0.0161,  0.0006, -0.0085],\n",
       "           [-0.0672,  0.0346,  0.0691],\n",
       "           [-0.0240,  0.1061,  0.0479]]],\n",
       " \n",
       " \n",
       "         [[[-0.0202, -0.0443,  0.0186],\n",
       "           [-0.0438,  0.0196, -0.0074],\n",
       "           [ 0.0589, -0.0774, -0.0242]],\n",
       " \n",
       "          [[ 0.0225, -0.0188,  0.0242],\n",
       "           [-0.0048,  0.0247, -0.0388],\n",
       "           [-0.0484, -0.0627, -0.0461]],\n",
       " \n",
       "          [[-0.0255,  0.0753,  0.0793],\n",
       "           [-0.0350,  0.0327, -0.0254],\n",
       "           [ 0.0231,  0.0689, -0.0412]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0103,  0.0650,  0.0051],\n",
       "           [-0.0042,  0.0073,  0.0653],\n",
       "           [-0.0342,  0.0374, -0.1171]],\n",
       " \n",
       "          [[-0.0934, -0.0244, -0.0703],\n",
       "           [-0.0033,  0.0118,  0.0115],\n",
       "           [ 0.0653, -0.0246,  0.0122]],\n",
       " \n",
       "          [[ 0.0084, -0.0139,  0.0298],\n",
       "           [-0.0136,  0.0083, -0.0211],\n",
       "           [ 0.0567, -0.0249, -0.0333]]],\n",
       " \n",
       " \n",
       "         [[[-0.0144, -0.0639, -0.0183],\n",
       "           [ 0.0146,  0.0391, -0.0140],\n",
       "           [-0.0960, -0.0019,  0.0168]],\n",
       " \n",
       "          [[ 0.0162, -0.0389, -0.0639],\n",
       "           [-0.0449,  0.0104, -0.0445],\n",
       "           [ 0.0108,  0.0177,  0.0489]],\n",
       " \n",
       "          [[-0.0204, -0.0233,  0.0153],\n",
       "           [ 0.0343,  0.0243, -0.0480],\n",
       "           [ 0.0417,  0.0915,  0.0376]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0201,  0.0783,  0.0344],\n",
       "           [ 0.0258,  0.0497, -0.0597],\n",
       "           [-0.0199, -0.0183,  0.0177]],\n",
       " \n",
       "          [[ 0.0128,  0.0255,  0.0458],\n",
       "           [-0.0274,  0.0332, -0.0038],\n",
       "           [ 0.0175, -0.0214, -0.0499]],\n",
       " \n",
       "          [[-0.0083,  0.0134,  0.0637],\n",
       "           [-0.0077, -0.0220, -0.0232],\n",
       "           [ 0.0226, -0.0407, -0.0132]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0139, -0.0510,  0.0308],\n",
       "           [-0.0364,  0.0217,  0.0492],\n",
       "           [ 0.0382,  0.0589, -0.0386]],\n",
       " \n",
       "          [[ 0.0300, -0.0343,  0.0233],\n",
       "           [ 0.0183, -0.0360,  0.0020],\n",
       "           [-0.0618,  0.0278, -0.0126]],\n",
       " \n",
       "          [[ 0.0201,  0.0875, -0.0218],\n",
       "           [ 0.0194,  0.0653, -0.0075],\n",
       "           [ 0.0097, -0.0022, -0.0390]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0512,  0.0194,  0.0264],\n",
       "           [-0.0672, -0.0130, -0.0255],\n",
       "           [ 0.0389,  0.0335, -0.0197]],\n",
       " \n",
       "          [[ 0.1110, -0.0124,  0.0038],\n",
       "           [ 0.0186, -0.0051,  0.0389],\n",
       "           [ 0.0028,  0.0141, -0.0274]],\n",
       " \n",
       "          [[-0.0425,  0.0716, -0.0506],\n",
       "           [-0.0526, -0.0534, -0.0270],\n",
       "           [-0.0201, -0.0542,  0.0739]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0019, -0.0421,  0.0595],\n",
       "           [-0.0261,  0.0263, -0.0015],\n",
       "           [ 0.0387,  0.0053,  0.0258]],\n",
       " \n",
       "          [[ 0.0151,  0.0915,  0.0601],\n",
       "           [-0.0070, -0.0063,  0.1218],\n",
       "           [-0.0038,  0.0628,  0.0442]],\n",
       " \n",
       "          [[-0.0406,  0.0286, -0.0308],\n",
       "           [-0.0209, -0.0023, -0.0153],\n",
       "           [-0.0452,  0.0291,  0.0268]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0157,  0.0076,  0.0186],\n",
       "           [-0.0446,  0.0026,  0.0250],\n",
       "           [ 0.0219,  0.0426,  0.0329]],\n",
       " \n",
       "          [[-0.0096,  0.0600,  0.0362],\n",
       "           [ 0.0294,  0.0516,  0.0623],\n",
       "           [-0.1110,  0.0111,  0.0521]],\n",
       " \n",
       "          [[ 0.0330,  0.0538,  0.0038],\n",
       "           [ 0.0685, -0.0105, -0.0438],\n",
       "           [ 0.0113, -0.0568, -0.0096]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0278,  0.0166,  0.0072],\n",
       "           [-0.0201, -0.0283,  0.0194],\n",
       "           [ 0.0705, -0.0240, -0.0203]],\n",
       " \n",
       "          [[-0.0050,  0.0336, -0.0041],\n",
       "           [-0.0391,  0.0378, -0.0418],\n",
       "           [ 0.0401,  0.0064,  0.0127]],\n",
       " \n",
       "          [[ 0.0817, -0.1035,  0.0064],\n",
       "           [-0.0177, -0.0028, -0.0287],\n",
       "           [ 0.0618, -0.0112,  0.0620]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0466,  0.0329,  0.0118],\n",
       "           [-0.0327, -0.0114,  0.0373],\n",
       "           [-0.0748,  0.0145,  0.0491]],\n",
       " \n",
       "          [[ 0.0084, -0.0312, -0.0275],\n",
       "           [ 0.0026, -0.0084, -0.0551],\n",
       "           [ 0.0084,  0.0553,  0.0858]],\n",
       " \n",
       "          [[ 0.0763, -0.0040, -0.0183],\n",
       "           [ 0.0334,  0.0195, -0.0037],\n",
       "           [ 0.0496,  0.0950,  0.0126]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0208,  0.0209,  0.0187],\n",
       "           [ 0.0195, -0.0022,  0.0512],\n",
       "           [-0.0026, -0.0193, -0.0042]],\n",
       " \n",
       "          [[-0.0049,  0.0346,  0.0113],\n",
       "           [ 0.0178, -0.0243,  0.0087],\n",
       "           [-0.0175, -0.0098,  0.0147]],\n",
       " \n",
       "          [[ 0.0738,  0.0215,  0.0360],\n",
       "           [ 0.0326, -0.0039,  0.0278],\n",
       "           [-0.0143, -0.0266, -0.0344]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0010,  0.0011, -0.0284],\n",
       "           [-0.0304,  0.0366,  0.0278],\n",
       "           [ 0.0226, -0.0067,  0.0128]],\n",
       " \n",
       "          [[ 0.0346,  0.0648,  0.0055],\n",
       "           [-0.0061,  0.0529,  0.0087],\n",
       "           [-0.0111, -0.0080, -0.0717]],\n",
       " \n",
       "          [[ 0.0155, -0.0243, -0.0169],\n",
       "           [ 0.0136, -0.0450, -0.0147],\n",
       "           [ 0.0412, -0.0512,  0.0299]]],\n",
       " \n",
       " \n",
       "         [[[-0.0099, -0.0020, -0.0158],\n",
       "           [ 0.0088,  0.0037,  0.0055],\n",
       "           [-0.0358,  0.0078,  0.0310]],\n",
       " \n",
       "          [[ 0.0215, -0.0079, -0.0021],\n",
       "           [ 0.0165,  0.0235, -0.0291],\n",
       "           [-0.0028, -0.0219,  0.0084]],\n",
       " \n",
       "          [[-0.0568, -0.0072,  0.0072],\n",
       "           [ 0.0079,  0.0354,  0.0512],\n",
       "           [-0.0374,  0.0143,  0.0245]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0184, -0.0086, -0.0401],\n",
       "           [ 0.0040,  0.0552,  0.0195],\n",
       "           [ 0.0568,  0.0028,  0.0017]],\n",
       " \n",
       "          [[ 0.0305, -0.0510,  0.0477],\n",
       "           [ 0.0475, -0.0466, -0.0311],\n",
       "           [ 0.0482,  0.0104,  0.0094]],\n",
       " \n",
       "          [[ 0.0483,  0.0328, -0.0954],\n",
       "           [ 0.0078,  0.0040, -0.0183],\n",
       "           [ 0.0137, -0.0155, -0.0606]]],\n",
       " \n",
       " \n",
       "         [[[-0.0207,  0.0119, -0.0129],\n",
       "           [-0.0159,  0.0305, -0.0398],\n",
       "           [ 0.0114,  0.0569, -0.0080]],\n",
       " \n",
       "          [[ 0.0117,  0.0632, -0.0109],\n",
       "           [ 0.0098, -0.0218, -0.0208],\n",
       "           [ 0.0007,  0.0060,  0.0040]],\n",
       " \n",
       "          [[ 0.0146,  0.0401,  0.0017],\n",
       "           [-0.0093, -0.0062, -0.0353],\n",
       "           [ 0.0044,  0.0210, -0.0394]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0099,  0.0359,  0.0336],\n",
       "           [-0.0211,  0.0190,  0.0267],\n",
       "           [ 0.0094,  0.0639, -0.0120]],\n",
       " \n",
       "          [[ 0.0454, -0.0096, -0.0018],\n",
       "           [ 0.0312, -0.0232, -0.0132],\n",
       "           [ 0.0106,  0.0145, -0.0135]],\n",
       " \n",
       "          [[-0.0188,  0.0051,  0.0240],\n",
       "           [ 0.0104,  0.0082,  0.0431],\n",
       "           [-0.0101, -0.0045,  0.0630]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0428, -0.0060, -0.0765],\n",
       "           [ 0.0026, -0.0001, -0.0023],\n",
       "           [ 0.0174,  0.0195, -0.0121]],\n",
       " \n",
       "          [[-0.0058,  0.0711,  0.0377],\n",
       "           [-0.0033, -0.0355, -0.0146],\n",
       "           [ 0.0299,  0.0800,  0.0545]],\n",
       " \n",
       "          [[-0.0348,  0.0061,  0.0058],\n",
       "           [-0.0375, -0.0095,  0.0089],\n",
       "           [ 0.0346, -0.0051,  0.0564]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0107, -0.0251,  0.0444],\n",
       "           [ 0.0353,  0.0236, -0.0341],\n",
       "           [ 0.0339,  0.0535, -0.0528]],\n",
       " \n",
       "          [[-0.0063, -0.0061, -0.0007],\n",
       "           [-0.0032,  0.0148, -0.0140],\n",
       "           [-0.0169,  0.0254,  0.0651]],\n",
       " \n",
       "          [[-0.0217,  0.0350,  0.0411],\n",
       "           [ 0.0154,  0.0049,  0.0106],\n",
       "           [ 0.0107, -0.0048, -0.0005]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0050, -0.0292, -0.0156],\n",
       "           [ 0.0097,  0.0609,  0.0592],\n",
       "           [ 0.0049,  0.0196, -0.0263]],\n",
       " \n",
       "          [[ 0.0660,  0.0263, -0.0098],\n",
       "           [-0.0033, -0.0248, -0.0104],\n",
       "           [ 0.0287, -0.0198, -0.0010]],\n",
       " \n",
       "          [[-0.0010,  0.0444,  0.0077],\n",
       "           [ 0.0298, -0.0361, -0.0053],\n",
       "           [ 0.0044, -0.0392, -0.0101]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0335,  0.0079, -0.0149],\n",
       "           [ 0.0439,  0.0260,  0.0290],\n",
       "           [ 0.0039, -0.0629,  0.0281]],\n",
       " \n",
       "          [[ 0.0231,  0.0072, -0.0364],\n",
       "           [ 0.0086, -0.0042, -0.0087],\n",
       "           [-0.0168,  0.0337, -0.0120]],\n",
       " \n",
       "          [[-0.0087, -0.0188, -0.0703],\n",
       "           [ 0.0159,  0.0058,  0.0246],\n",
       "           [-0.0406,  0.0465,  0.0100]]],\n",
       " \n",
       " \n",
       "         [[[-0.0098,  0.0079,  0.0127],\n",
       "           [ 0.0211,  0.0376, -0.0062],\n",
       "           [-0.0020, -0.0042, -0.0129]],\n",
       " \n",
       "          [[ 0.0251, -0.0181,  0.0073],\n",
       "           [ 0.0430, -0.0514,  0.0195],\n",
       "           [ 0.0104, -0.0143,  0.0347]],\n",
       " \n",
       "          [[-0.0397, -0.0413, -0.0101],\n",
       "           [-0.0221, -0.0451, -0.0456],\n",
       "           [ 0.0008,  0.0248, -0.0471]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0372, -0.0176,  0.0162],\n",
       "           [-0.0387, -0.0053,  0.0060],\n",
       "           [-0.0163, -0.0033,  0.0172]],\n",
       " \n",
       "          [[-0.0042,  0.0285, -0.0178],\n",
       "           [ 0.0036,  0.0306, -0.0326],\n",
       "           [-0.0037, -0.0414,  0.0124]],\n",
       " \n",
       "          [[-0.0153, -0.0182, -0.0021],\n",
       "           [ 0.0095, -0.0175,  0.0045],\n",
       "           [ 0.0426,  0.0145, -0.0308]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0154, -0.0033, -0.0338],\n",
       "           [-0.0111, -0.0082, -0.0104],\n",
       "           [ 0.0246, -0.0163,  0.0047]],\n",
       " \n",
       "          [[ 0.0094, -0.0128, -0.0259],\n",
       "           [ 0.0129, -0.0444, -0.0313],\n",
       "           [-0.0137, -0.0473, -0.0334]],\n",
       " \n",
       "          [[-0.0105,  0.0138, -0.0450],\n",
       "           [ 0.0190,  0.0021, -0.0583],\n",
       "           [ 0.0169, -0.0231,  0.0102]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0043,  0.0858,  0.0217],\n",
       "           [ 0.0174,  0.0172, -0.0168],\n",
       "           [-0.0152,  0.0699, -0.0064]],\n",
       " \n",
       "          [[ 0.0415, -0.0477,  0.0225],\n",
       "           [-0.0082,  0.0094, -0.0364],\n",
       "           [-0.0170, -0.0136, -0.0317]],\n",
       " \n",
       "          [[-0.0464, -0.0279, -0.0669],\n",
       "           [-0.0004,  0.0314, -0.0096],\n",
       "           [ 0.0236, -0.0207, -0.0369]]],\n",
       " \n",
       " \n",
       "         [[[-0.0044, -0.0772, -0.0009],\n",
       "           [-0.0126, -0.0422,  0.0095],\n",
       "           [-0.0689,  0.0207,  0.0227]],\n",
       " \n",
       "          [[ 0.0127, -0.0151,  0.0145],\n",
       "           [ 0.0093, -0.0123,  0.0345],\n",
       "           [ 0.0102,  0.0071, -0.0177]],\n",
       " \n",
       "          [[ 0.0247, -0.0033, -0.0265],\n",
       "           [ 0.0023, -0.0128,  0.0064],\n",
       "           [-0.0058,  0.0135,  0.0080]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0006, -0.0477,  0.0347],\n",
       "           [ 0.0383,  0.0228, -0.0254],\n",
       "           [-0.0350,  0.0564, -0.0355]],\n",
       " \n",
       "          [[ 0.0210,  0.0480, -0.0537],\n",
       "           [ 0.0269, -0.0005, -0.0109],\n",
       "           [-0.0597,  0.0219, -0.0068]],\n",
       " \n",
       "          [[ 0.0012,  0.0088, -0.0491],\n",
       "           [ 0.0088,  0.0064,  0.0530],\n",
       "           [-0.0316,  0.0085,  0.0812]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0187, -0.0153,  0.0354],\n",
       "           [-0.0198,  0.0511, -0.0081],\n",
       "           [ 0.0118,  0.0321, -0.0096]],\n",
       " \n",
       "          [[-0.0153,  0.0470,  0.0028],\n",
       "           [ 0.0037, -0.0359,  0.0409],\n",
       "           [ 0.0280,  0.0058, -0.0626]],\n",
       " \n",
       "          [[-0.0244,  0.0319, -0.0014],\n",
       "           [ 0.0132, -0.0240, -0.0453],\n",
       "           [ 0.0008,  0.0212, -0.0044]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0408, -0.0203,  0.0016],\n",
       "           [ 0.0347, -0.0040, -0.0487],\n",
       "           [-0.0055,  0.0284,  0.0196]],\n",
       " \n",
       "          [[ 0.0233,  0.0404,  0.0106],\n",
       "           [ 0.0323,  0.0324,  0.0398],\n",
       "           [ 0.0158,  0.0457, -0.0620]],\n",
       " \n",
       "          [[-0.0465, -0.0575, -0.0085],\n",
       "           [ 0.0622, -0.0066,  0.0037],\n",
       "           [-0.0058, -0.0091, -0.0020]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0158,  0.0051,  0.0268],\n",
       "           [ 0.0167,  0.0075, -0.0369],\n",
       "           [-0.0493,  0.0164,  0.0067]],\n",
       " \n",
       "          [[-0.0244, -0.0023, -0.0216],\n",
       "           [-0.0183,  0.0137,  0.0172],\n",
       "           [ 0.0187, -0.0350, -0.0522]],\n",
       " \n",
       "          [[-0.0193, -0.0391, -0.0433],\n",
       "           [ 0.0304, -0.0288, -0.0249],\n",
       "           [-0.0100,  0.0497, -0.0323]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0014,  0.0089,  0.0528],\n",
       "           [ 0.0280,  0.0039,  0.0109],\n",
       "           [ 0.0219,  0.0433, -0.0257]],\n",
       " \n",
       "          [[ 0.0302,  0.0521,  0.0160],\n",
       "           [-0.0167, -0.0088, -0.0161],\n",
       "           [-0.0095, -0.0097,  0.0147]],\n",
       " \n",
       "          [[-0.0364, -0.0117,  0.0113],\n",
       "           [-0.0050, -0.0327,  0.0346],\n",
       "           [ 0.0169, -0.0310, -0.0161]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0063,  0.0529,  0.0092],\n",
       "           [ 0.0143, -0.0122, -0.0036],\n",
       "           [ 0.0306,  0.0332, -0.0221]],\n",
       " \n",
       "          [[-0.0082, -0.0240, -0.0486],\n",
       "           [ 0.0160,  0.0453,  0.0142],\n",
       "           [ 0.0210, -0.0331,  0.0785]],\n",
       " \n",
       "          [[ 0.0067,  0.0130,  0.0237],\n",
       "           [-0.0239, -0.0244, -0.0027],\n",
       "           [-0.0424, -0.0210, -0.0293]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0110, -0.0269, -0.0103],\n",
       "           [-0.0153, -0.0078, -0.0163],\n",
       "           [-0.0334,  0.0079,  0.0168]],\n",
       " \n",
       "          [[ 0.0201, -0.0469, -0.0187],\n",
       "           [ 0.0025,  0.0742, -0.0042],\n",
       "           [ 0.0290, -0.0297, -0.0251]],\n",
       " \n",
       "          [[-0.0403, -0.0208, -0.0412],\n",
       "           [-0.0330,  0.0703, -0.0348],\n",
       "           [ 0.0054, -0.0066,  0.0349]]],\n",
       " \n",
       " \n",
       "         [[[-0.0005,  0.0305,  0.0570],\n",
       "           [ 0.0243,  0.0232, -0.0483],\n",
       "           [-0.0015, -0.0497, -0.0184]],\n",
       " \n",
       "          [[-0.0124,  0.0633, -0.0151],\n",
       "           [ 0.0590, -0.0371,  0.0144],\n",
       "           [-0.0425,  0.0105, -0.0088]],\n",
       " \n",
       "          [[ 0.0256, -0.0544,  0.0267],\n",
       "           [-0.0339,  0.0035,  0.0117],\n",
       "           [-0.0298, -0.0043,  0.0013]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0341,  0.0072, -0.0097],\n",
       "           [-0.0459, -0.0246,  0.0241],\n",
       "           [ 0.0021,  0.0333,  0.0151]],\n",
       " \n",
       "          [[ 0.0235, -0.0376,  0.0210],\n",
       "           [ 0.0407,  0.0408,  0.0018],\n",
       "           [-0.0110, -0.0077,  0.0642]],\n",
       " \n",
       "          [[-0.0255, -0.0089, -0.0226],\n",
       "           [ 0.0100,  0.0119,  0.0171],\n",
       "           [ 0.0080,  0.0196,  0.0283]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.1373]],\n",
       " \n",
       "          [[ 0.0432]],\n",
       " \n",
       "          [[ 0.1557]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1119]],\n",
       " \n",
       "          [[-0.0508]],\n",
       " \n",
       "          [[-0.0690]]],\n",
       " \n",
       " \n",
       "         [[[-0.0026]],\n",
       " \n",
       "          [[ 0.0564]],\n",
       " \n",
       "          [[ 0.1637]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1857]],\n",
       " \n",
       "          [[-0.0500]],\n",
       " \n",
       "          [[-0.1318]]],\n",
       " \n",
       " \n",
       "         [[[-0.1230]],\n",
       " \n",
       "          [[-0.0854]],\n",
       " \n",
       "          [[ 0.1497]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0734]],\n",
       " \n",
       "          [[ 0.0220]],\n",
       " \n",
       "          [[-0.0673]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0131]],\n",
       " \n",
       "          [[-0.0026]],\n",
       " \n",
       "          [[ 0.0180]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.1057]],\n",
       " \n",
       "          [[-0.0390]],\n",
       " \n",
       "          [[-0.0077]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0166]],\n",
       " \n",
       "          [[ 0.0581]],\n",
       " \n",
       "          [[-0.0450]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0445]],\n",
       " \n",
       "          [[-0.1062]],\n",
       " \n",
       "          [[ 0.0694]]],\n",
       " \n",
       " \n",
       "         [[[-0.0324]],\n",
       " \n",
       "          [[ 0.0705]],\n",
       " \n",
       "          [[ 0.1111]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0160]],\n",
       " \n",
       "          [[ 0.1403]],\n",
       " \n",
       "          [[ 0.0652]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-2.3834e-02,  5.9942e-03, -4.0970e-03],\n",
       "           [ 1.7785e-02, -2.4559e-02,  2.2555e-02],\n",
       "           [-8.3909e-02,  2.1893e-02, -3.0755e-02]],\n",
       " \n",
       "          [[ 1.9667e-02,  6.2503e-02,  2.1289e-02],\n",
       "           [ 2.4708e-02,  5.3403e-02,  2.2346e-02],\n",
       "           [ 2.0230e-02,  2.4084e-02,  1.9453e-03]],\n",
       " \n",
       "          [[-2.6276e-02,  1.2030e-02,  1.1033e-02],\n",
       "           [ 2.7466e-02, -2.4903e-02,  3.1106e-02],\n",
       "           [ 7.6803e-04, -1.1384e-02,  8.0138e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5272e-02,  9.2449e-03,  3.1826e-03],\n",
       "           [ 1.6122e-02,  4.3740e-02, -4.6023e-03],\n",
       "           [-6.1682e-02, -2.3026e-02,  1.2947e-03]],\n",
       " \n",
       "          [[ 3.4116e-02, -6.2883e-02, -7.5692e-03],\n",
       "           [ 3.4309e-05,  3.9920e-03, -2.1948e-02],\n",
       "           [ 4.2816e-03, -3.1549e-02, -5.4656e-03]],\n",
       " \n",
       "          [[ 3.7320e-02,  1.2590e-02,  3.2428e-03],\n",
       "           [ 2.6114e-02, -9.6812e-04,  4.0851e-02],\n",
       "           [-3.8101e-02,  2.7489e-02,  2.8925e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.8634e-02,  6.0691e-02, -1.6510e-02],\n",
       "           [-1.9978e-02,  1.9792e-02,  1.3429e-02],\n",
       "           [-1.5258e-02,  5.2302e-02,  1.6860e-02]],\n",
       " \n",
       "          [[-2.9754e-02, -1.2020e-02, -2.2408e-02],\n",
       "           [-3.9478e-03, -1.0244e-02,  4.9328e-02],\n",
       "           [ 4.3743e-02,  2.1420e-02, -2.5649e-02]],\n",
       " \n",
       "          [[-4.6614e-03,  7.3819e-04, -9.8019e-03],\n",
       "           [-6.5509e-03, -2.1368e-03,  1.8067e-02],\n",
       "           [-1.4225e-02, -4.2583e-02,  6.8416e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.6583e-03, -1.0681e-02,  3.8775e-02],\n",
       "           [-3.6634e-02,  2.4650e-04,  5.8685e-03],\n",
       "           [ 5.6101e-02,  4.9382e-03,  5.1936e-02]],\n",
       " \n",
       "          [[-1.9232e-02,  3.3394e-02,  1.0881e-02],\n",
       "           [ 2.6594e-02,  1.2801e-03,  6.3945e-02],\n",
       "           [-4.0309e-02, -2.7196e-02, -5.7233e-02]],\n",
       " \n",
       "          [[ 3.3095e-03,  2.1482e-02,  4.4145e-02],\n",
       "           [-2.1891e-02,  1.5338e-02, -1.3141e-02],\n",
       "           [-1.9847e-02,  4.6251e-02, -1.6823e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2512e-02,  1.9936e-03,  6.5944e-02],\n",
       "           [ 5.4904e-02, -4.0350e-02,  1.0248e-02],\n",
       "           [-1.3726e-02,  3.0433e-02, -2.3960e-02]],\n",
       " \n",
       "          [[-4.2685e-02,  1.0218e-03, -5.7144e-02],\n",
       "           [-2.8391e-02,  1.0800e-02, -2.0237e-03],\n",
       "           [-7.7351e-04,  9.0732e-04, -1.8698e-02]],\n",
       " \n",
       "          [[-5.6418e-03,  2.2849e-02, -2.7175e-02],\n",
       "           [-3.3529e-02, -5.7200e-02, -1.5621e-02],\n",
       "           [ 1.1206e-02,  1.4845e-02,  1.0183e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7886e-02, -1.1121e-02, -4.0666e-02],\n",
       "           [-5.7948e-02,  3.1416e-02,  2.7112e-02],\n",
       "           [ 1.3427e-02,  5.8973e-02, -1.1565e-02]],\n",
       " \n",
       "          [[ 1.8862e-02,  4.7649e-04,  3.1472e-02],\n",
       "           [ 3.7768e-02, -1.4530e-02,  3.3065e-02],\n",
       "           [ 1.3047e-02, -1.1667e-02, -2.2945e-02]],\n",
       " \n",
       "          [[ 4.9328e-02,  1.9014e-02, -4.9946e-03],\n",
       "           [ 3.5105e-02, -4.8089e-02,  1.2110e-02],\n",
       "           [-6.7804e-03,  2.4726e-02,  4.2153e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-6.2902e-03,  5.9946e-02, -1.9444e-02],\n",
       "           [ 2.2750e-02, -1.9039e-02, -3.4588e-02],\n",
       "           [ 6.8217e-02,  1.0446e-02,  4.0006e-02]],\n",
       " \n",
       "          [[ 1.2085e-04, -3.7902e-02,  1.0523e-02],\n",
       "           [-1.6386e-02, -2.5679e-02, -3.3993e-03],\n",
       "           [-1.3451e-02,  6.4194e-02,  5.4399e-03]],\n",
       " \n",
       "          [[-3.2864e-02, -1.0664e-02,  1.3784e-02],\n",
       "           [ 4.4938e-03, -2.6469e-02,  2.9641e-02],\n",
       "           [ 3.9787e-03,  2.0169e-02, -3.2190e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.9272e-02, -2.8266e-02, -4.5101e-02],\n",
       "           [-2.3528e-02, -1.6718e-02,  2.3004e-02],\n",
       "           [-4.8410e-02, -2.2794e-03, -3.3041e-02]],\n",
       " \n",
       "          [[-3.8898e-02, -2.1164e-02,  1.2119e-02],\n",
       "           [-3.4413e-02, -1.9015e-02, -3.2065e-03],\n",
       "           [ 6.3184e-02,  2.2988e-02,  3.6300e-02]],\n",
       " \n",
       "          [[ 8.5891e-03,  1.0195e-03, -5.0570e-02],\n",
       "           [-4.5847e-02,  3.9894e-02, -2.0133e-02],\n",
       "           [-4.0673e-02, -6.6698e-02,  2.1189e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.4166e-03,  3.5416e-02,  8.5514e-03],\n",
       "           [ 1.1568e-02,  3.6340e-03,  1.6354e-02],\n",
       "           [ 1.3076e-02, -2.0806e-02, -3.5361e-04]],\n",
       " \n",
       "          [[-1.4142e-02, -3.4718e-02, -2.6146e-02],\n",
       "           [-2.8452e-03,  2.6422e-03, -4.6200e-02],\n",
       "           [-2.4543e-02,  9.7269e-03,  1.5254e-02]],\n",
       " \n",
       "          [[-1.1943e-02, -8.2090e-02, -5.5414e-03],\n",
       "           [ 2.0296e-02,  8.1264e-03,  1.9335e-02],\n",
       "           [ 2.1554e-02, -4.7368e-02, -3.7317e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.9372e-03, -8.0331e-04,  2.1308e-02],\n",
       "           [-5.0620e-02, -9.0506e-03, -2.9026e-02],\n",
       "           [ 3.4566e-02, -1.9442e-02, -6.7717e-02]],\n",
       " \n",
       "          [[-3.7792e-02, -6.5845e-04, -1.9303e-02],\n",
       "           [-3.5623e-02, -2.4430e-02,  4.3604e-03],\n",
       "           [ 3.2519e-03, -2.7046e-02, -2.8568e-02]],\n",
       " \n",
       "          [[ 7.8898e-04, -4.0727e-02,  5.4281e-02],\n",
       "           [-3.2568e-03, -1.6285e-02,  6.1041e-02],\n",
       "           [ 2.1653e-02,  2.5507e-02,  1.9332e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3157e-02, -2.7643e-02, -1.9476e-02],\n",
       "           [ 4.6601e-02, -9.8293e-03,  6.8800e-02],\n",
       "           [ 6.9660e-02,  3.2693e-03,  1.3723e-02]],\n",
       " \n",
       "          [[ 4.8281e-04, -1.0948e-02, -1.6763e-02],\n",
       "           [ 1.2394e-02,  7.6953e-03,  2.1895e-02],\n",
       "           [-3.9279e-02,  6.6286e-04,  2.0804e-02]],\n",
       " \n",
       "          [[-4.5962e-02,  3.3170e-02,  5.8382e-02],\n",
       "           [-6.8797e-02,  3.4032e-02, -3.0415e-02],\n",
       "           [ 1.1377e-02, -1.2774e-02,  4.1181e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0871e-02, -4.7120e-02,  2.7291e-03],\n",
       "           [ 9.9565e-03,  2.4821e-02,  4.6581e-04],\n",
       "           [-4.2657e-02,  1.5231e-02, -8.5758e-03]],\n",
       " \n",
       "          [[ 7.7085e-03,  5.8156e-02, -2.4874e-02],\n",
       "           [ 2.2144e-03, -3.0407e-02,  2.8661e-02],\n",
       "           [-6.1774e-02,  1.7807e-02, -6.2731e-03]],\n",
       " \n",
       "          [[ 5.8831e-02,  4.3629e-02, -2.7019e-02],\n",
       "           [ 8.2549e-03, -1.5336e-02,  6.9256e-02],\n",
       "           [ 1.8270e-02,  6.5882e-02,  1.1501e-02]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0659,  0.0360, -0.0266],\n",
       "           [ 0.0067, -0.0522, -0.0508],\n",
       "           [-0.0202,  0.0557,  0.0053]],\n",
       " \n",
       "          [[-0.0012,  0.0072,  0.0469],\n",
       "           [ 0.0074, -0.0293,  0.0046],\n",
       "           [-0.0371,  0.0005, -0.0305]],\n",
       " \n",
       "          [[-0.0299, -0.0010,  0.0126],\n",
       "           [-0.0630, -0.0063,  0.0670],\n",
       "           [ 0.0239, -0.0037,  0.0282]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0093,  0.0379, -0.0198],\n",
       "           [ 0.0103,  0.0340, -0.0231],\n",
       "           [-0.0215, -0.0302,  0.0050]],\n",
       " \n",
       "          [[-0.0015, -0.0140,  0.0118],\n",
       "           [ 0.0243,  0.0288, -0.0003],\n",
       "           [ 0.0320, -0.0045,  0.0236]],\n",
       " \n",
       "          [[ 0.0194,  0.0207, -0.0278],\n",
       "           [-0.0038,  0.0402, -0.0294],\n",
       "           [-0.0101, -0.0228, -0.0075]]],\n",
       " \n",
       " \n",
       "         [[[-0.0073, -0.0043, -0.0565],\n",
       "           [ 0.0151,  0.0087,  0.0085],\n",
       "           [ 0.0240, -0.0238, -0.0018]],\n",
       " \n",
       "          [[-0.0284, -0.0146,  0.0141],\n",
       "           [-0.0198, -0.0116, -0.0054],\n",
       "           [ 0.0474, -0.0229, -0.0435]],\n",
       " \n",
       "          [[ 0.0024, -0.0086, -0.0185],\n",
       "           [ 0.0021, -0.0155, -0.0061],\n",
       "           [-0.0227, -0.0219,  0.0187]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0442, -0.0194,  0.0543],\n",
       "           [-0.0155, -0.0328,  0.0375],\n",
       "           [-0.0136, -0.0165, -0.0117]],\n",
       " \n",
       "          [[ 0.0215, -0.0130, -0.0266],\n",
       "           [-0.0403,  0.0091, -0.0183],\n",
       "           [-0.0027,  0.0303, -0.0175]],\n",
       " \n",
       "          [[-0.0323, -0.0033, -0.0603],\n",
       "           [ 0.0057,  0.0337,  0.0294],\n",
       "           [-0.0264,  0.0281,  0.0566]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0043, -0.0130, -0.0047],\n",
       "           [-0.0213,  0.0036, -0.0283],\n",
       "           [-0.0451, -0.0428, -0.0137]],\n",
       " \n",
       "          [[-0.0072,  0.0063, -0.0083],\n",
       "           [ 0.0345,  0.0108,  0.0506],\n",
       "           [-0.0231,  0.0215,  0.0101]],\n",
       " \n",
       "          [[-0.0187, -0.0080,  0.0003],\n",
       "           [ 0.0104,  0.0352,  0.0349],\n",
       "           [-0.0393, -0.0075, -0.0606]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0576, -0.0148, -0.0215],\n",
       "           [-0.0503, -0.0176,  0.0070],\n",
       "           [ 0.0349, -0.0468, -0.0215]],\n",
       " \n",
       "          [[-0.0422, -0.0171, -0.0141],\n",
       "           [-0.0230, -0.0246, -0.0137],\n",
       "           [ 0.0223,  0.0161, -0.0188]],\n",
       " \n",
       "          [[ 0.0375,  0.0372, -0.0378],\n",
       "           [ 0.0004, -0.0346, -0.0366],\n",
       "           [ 0.0057,  0.0357, -0.0520]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0174,  0.0289,  0.0559],\n",
       "           [-0.0051,  0.0341, -0.0520],\n",
       "           [ 0.0050,  0.0097,  0.0018]],\n",
       " \n",
       "          [[ 0.0221,  0.0397, -0.0888],\n",
       "           [-0.0266,  0.0153, -0.0291],\n",
       "           [-0.0407, -0.0346, -0.0506]],\n",
       " \n",
       "          [[ 0.0048, -0.0239,  0.0399],\n",
       "           [ 0.0520,  0.0023, -0.0180],\n",
       "           [-0.0251,  0.0306, -0.0067]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0291, -0.0017,  0.0181],\n",
       "           [-0.0386,  0.0274, -0.0079],\n",
       "           [-0.0219, -0.0016,  0.0231]],\n",
       " \n",
       "          [[-0.0225,  0.0307, -0.0444],\n",
       "           [ 0.0115,  0.0586, -0.0289],\n",
       "           [-0.0025,  0.0237,  0.0314]],\n",
       " \n",
       "          [[ 0.0459,  0.0159, -0.0113],\n",
       "           [-0.0076,  0.0617, -0.0147],\n",
       "           [-0.0022,  0.0593, -0.0423]]],\n",
       " \n",
       " \n",
       "         [[[-0.0369,  0.0001,  0.0412],\n",
       "           [-0.0679,  0.0211,  0.0276],\n",
       "           [ 0.0277,  0.0539,  0.0056]],\n",
       " \n",
       "          [[ 0.0326, -0.0378, -0.0264],\n",
       "           [ 0.0021,  0.0386, -0.0020],\n",
       "           [-0.0247, -0.0130,  0.0295]],\n",
       " \n",
       "          [[-0.0191,  0.0306, -0.0637],\n",
       "           [ 0.0135,  0.0229,  0.0178],\n",
       "           [-0.0188,  0.0064, -0.0194]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0443,  0.0029,  0.0044],\n",
       "           [ 0.0175, -0.0319,  0.0335],\n",
       "           [ 0.0309,  0.0305, -0.0180]],\n",
       " \n",
       "          [[ 0.0153, -0.0113, -0.0195],\n",
       "           [-0.0126,  0.0154, -0.0010],\n",
       "           [-0.0346,  0.0066, -0.0306]],\n",
       " \n",
       "          [[ 0.0226, -0.0015,  0.0361],\n",
       "           [ 0.0199, -0.0629, -0.0179],\n",
       "           [ 0.0119,  0.0459, -0.0189]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0203,  0.0492,  0.0149],\n",
       "           [ 0.0389,  0.0061,  0.0012],\n",
       "           [ 0.0467, -0.0152,  0.0463]],\n",
       " \n",
       "          [[ 0.0225,  0.0755,  0.0102],\n",
       "           [ 0.0185,  0.0020, -0.0394],\n",
       "           [ 0.0291, -0.0081, -0.0125]],\n",
       " \n",
       "          [[-0.0171,  0.0394, -0.0282],\n",
       "           [ 0.0577,  0.0207,  0.0005],\n",
       "           [ 0.0165, -0.0122, -0.0568]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0040, -0.0407,  0.0536],\n",
       "           [ 0.0202,  0.0546,  0.0435],\n",
       "           [-0.0607,  0.0212, -0.0177]],\n",
       " \n",
       "          [[-0.0054, -0.0119,  0.0267],\n",
       "           [ 0.0480, -0.0320, -0.0151],\n",
       "           [ 0.0306,  0.0041,  0.0086]],\n",
       " \n",
       "          [[-0.0506, -0.0324, -0.0153],\n",
       "           [-0.0147, -0.0375,  0.0269],\n",
       "           [-0.0069,  0.0138, -0.0478]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0179,  0.0004,  0.0074],\n",
       "           [-0.0228, -0.0212,  0.0288],\n",
       "           [-0.0240, -0.0323, -0.0043]],\n",
       " \n",
       "          [[-0.0200,  0.0205, -0.0104],\n",
       "           [-0.0006,  0.0012,  0.0385],\n",
       "           [-0.0131,  0.0150, -0.0324]],\n",
       " \n",
       "          [[-0.0210, -0.0379, -0.0161],\n",
       "           [-0.0112,  0.0061,  0.0261],\n",
       "           [-0.0335, -0.0142,  0.0143]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0272, -0.0259,  0.0099],\n",
       "           [-0.0081, -0.0263,  0.0273],\n",
       "           [ 0.0117, -0.0209, -0.0184]],\n",
       " \n",
       "          [[-0.0126,  0.0416, -0.0064],\n",
       "           [-0.0019, -0.0204,  0.0027],\n",
       "           [-0.0030, -0.0013, -0.0021]],\n",
       " \n",
       "          [[ 0.0046, -0.0097,  0.0092],\n",
       "           [-0.0015, -0.0102,  0.0127],\n",
       "           [ 0.0012,  0.0339,  0.0102]]],\n",
       " \n",
       " \n",
       "         [[[-0.0068,  0.0334, -0.0181],\n",
       "           [ 0.0333, -0.0051, -0.0032],\n",
       "           [-0.0133, -0.0350,  0.0148]],\n",
       " \n",
       "          [[ 0.0334,  0.0206,  0.0122],\n",
       "           [ 0.0189,  0.0181, -0.0154],\n",
       "           [ 0.0161,  0.0421,  0.0011]],\n",
       " \n",
       "          [[ 0.0239, -0.0082, -0.0264],\n",
       "           [ 0.0030,  0.0191,  0.0001],\n",
       "           [-0.0061, -0.0018, -0.0049]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0021, -0.0121, -0.0067],\n",
       "           [ 0.0008,  0.0200,  0.0132],\n",
       "           [-0.0168, -0.0006,  0.0348]],\n",
       " \n",
       "          [[ 0.0551,  0.0504, -0.0436],\n",
       "           [-0.0127, -0.0175,  0.0516],\n",
       "           [ 0.0215,  0.0389,  0.0225]],\n",
       " \n",
       "          [[-0.0466, -0.0273, -0.0320],\n",
       "           [-0.0115, -0.0072, -0.0009],\n",
       "           [-0.0435,  0.0199,  0.0257]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0126, -0.0346,  0.0091],\n",
       "           [-0.0021,  0.0336, -0.0090],\n",
       "           [ 0.0301,  0.0027,  0.0093]],\n",
       " \n",
       "          [[-0.0359,  0.0147,  0.0037],\n",
       "           [ 0.0165, -0.0301,  0.0108],\n",
       "           [-0.0301,  0.0091, -0.0138]],\n",
       " \n",
       "          [[ 0.0277,  0.0140, -0.0094],\n",
       "           [ 0.0310,  0.0033, -0.0066],\n",
       "           [-0.0267,  0.0121, -0.0405]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0115, -0.0401,  0.0203],\n",
       "           [ 0.0120,  0.0051, -0.0173],\n",
       "           [-0.0303, -0.0139, -0.0045]],\n",
       " \n",
       "          [[-0.0068,  0.0095, -0.0068],\n",
       "           [-0.0072, -0.0335,  0.0017],\n",
       "           [ 0.0302, -0.0245,  0.0266]],\n",
       " \n",
       "          [[ 0.0081,  0.0006,  0.0039],\n",
       "           [-0.0062, -0.0424,  0.0018],\n",
       "           [ 0.0304,  0.0002,  0.0095]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0183,  0.0354, -0.0137],\n",
       "           [ 0.0284, -0.0182,  0.0021],\n",
       "           [ 0.0344, -0.0061, -0.0166]],\n",
       " \n",
       "          [[ 0.0009,  0.0177, -0.0004],\n",
       "           [-0.0100, -0.0192,  0.0362],\n",
       "           [-0.0106, -0.0078, -0.0310]],\n",
       " \n",
       "          [[-0.0251,  0.0252, -0.0445],\n",
       "           [ 0.0287, -0.0340, -0.0147],\n",
       "           [-0.0205,  0.0220, -0.0105]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0065, -0.0074, -0.0117],\n",
       "           [ 0.0203, -0.0068, -0.0288],\n",
       "           [ 0.0207,  0.0169, -0.0273]],\n",
       " \n",
       "          [[-0.0155,  0.0071,  0.0012],\n",
       "           [ 0.0040, -0.0217,  0.0125],\n",
       "           [ 0.0072, -0.0226,  0.0229]],\n",
       " \n",
       "          [[-0.0223, -0.0290,  0.0059],\n",
       "           [ 0.0065, -0.0488,  0.0013],\n",
       "           [-0.0094,  0.0236,  0.0398]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0019, -0.0143, -0.0025],\n",
       "           [ 0.0009,  0.0122,  0.0109],\n",
       "           [ 0.0058,  0.0031, -0.0172]],\n",
       " \n",
       "          [[ 0.0075,  0.0120, -0.0358],\n",
       "           [ 0.0036, -0.0014,  0.0095],\n",
       "           [ 0.0054,  0.0206,  0.0140]],\n",
       " \n",
       "          [[ 0.0355,  0.0385, -0.0060],\n",
       "           [ 0.0134,  0.0041, -0.0570],\n",
       "           [ 0.0103,  0.0416, -0.0053]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0014, -0.0013,  0.0254],\n",
       "           [-0.0251,  0.0488, -0.0250],\n",
       "           [ 0.0065, -0.0047,  0.0253]],\n",
       " \n",
       "          [[-0.0241, -0.0262,  0.0008],\n",
       "           [ 0.0393,  0.0154, -0.0164],\n",
       "           [-0.0601, -0.0221, -0.0213]],\n",
       " \n",
       "          [[-0.0054,  0.0038, -0.0198],\n",
       "           [ 0.0446,  0.0232,  0.0082],\n",
       "           [ 0.0204,  0.0091, -0.0066]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0023,  0.0182,  0.0127],\n",
       "           [-0.0036, -0.0222, -0.0047],\n",
       "           [ 0.0310, -0.0046, -0.0408]],\n",
       " \n",
       "          [[-0.0239,  0.0261, -0.0298],\n",
       "           [ 0.0062, -0.0267,  0.0095],\n",
       "           [-0.0219,  0.0618,  0.0273]],\n",
       " \n",
       "          [[-0.0071, -0.0018, -0.0192],\n",
       "           [ 0.0165, -0.0217,  0.0002],\n",
       "           [-0.0169,  0.0144, -0.0221]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0157, -0.0016,  0.0073],\n",
       "           [-0.0104, -0.0214,  0.0072],\n",
       "           [ 0.0384,  0.0090, -0.0052]],\n",
       " \n",
       "          [[-0.0303,  0.0164,  0.0154],\n",
       "           [ 0.0116,  0.0170,  0.0119],\n",
       "           [ 0.0156, -0.0101,  0.0037]],\n",
       " \n",
       "          [[ 0.0188,  0.0187,  0.0159],\n",
       "           [-0.0078,  0.0093, -0.0307],\n",
       "           [ 0.0095,  0.0242,  0.0182]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0142, -0.0163, -0.0044],\n",
       "           [ 0.0071,  0.0139,  0.0230],\n",
       "           [ 0.0112, -0.0093,  0.0144]],\n",
       " \n",
       "          [[-0.0007, -0.0160,  0.0125],\n",
       "           [-0.0014, -0.0039,  0.0068],\n",
       "           [-0.0106,  0.0283,  0.0283]],\n",
       " \n",
       "          [[-0.0414,  0.0077, -0.0284],\n",
       "           [ 0.0380, -0.0120,  0.0344],\n",
       "           [-0.0006,  0.0408, -0.0260]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0258,  0.0019, -0.0087],\n",
       "           [ 0.0237, -0.0138,  0.0092],\n",
       "           [ 0.0277,  0.0098, -0.0131]],\n",
       " \n",
       "          [[-0.0146,  0.0058, -0.0044],\n",
       "           [ 0.0332,  0.0027, -0.0204],\n",
       "           [-0.0008, -0.0078, -0.0009]],\n",
       " \n",
       "          [[-0.0312,  0.0361,  0.0035],\n",
       "           [ 0.0035, -0.0266,  0.0009],\n",
       "           [-0.0132,  0.0013,  0.0017]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0301,  0.0167, -0.0146],\n",
       "           [-0.0090, -0.0259, -0.0151],\n",
       "           [ 0.0087,  0.0011, -0.0090]],\n",
       " \n",
       "          [[-0.0284,  0.0106,  0.0326],\n",
       "           [ 0.0202, -0.0092, -0.0099],\n",
       "           [ 0.0016, -0.0194,  0.0210]],\n",
       " \n",
       "          [[-0.0046, -0.0318,  0.0291],\n",
       "           [-0.0112,  0.0006, -0.0233],\n",
       "           [ 0.0107,  0.0114,  0.0007]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0394, -0.0132, -0.0180],\n",
       "           [ 0.0058,  0.0120,  0.0228],\n",
       "           [ 0.0140,  0.0043, -0.0227]],\n",
       " \n",
       "          [[-0.0080,  0.0178, -0.0009],\n",
       "           [-0.0065, -0.0149,  0.0762],\n",
       "           [ 0.0047,  0.0197, -0.0127]],\n",
       " \n",
       "          [[ 0.0322, -0.0181,  0.0236],\n",
       "           [-0.0026, -0.0084, -0.0047],\n",
       "           [ 0.0089, -0.0108,  0.0148]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0057,  0.0559, -0.0099],\n",
       "           [ 0.0060,  0.0002, -0.0175],\n",
       "           [-0.0185,  0.0082,  0.0086]],\n",
       " \n",
       "          [[-0.0272,  0.0197, -0.0047],\n",
       "           [-0.0276, -0.0344,  0.0136],\n",
       "           [-0.0181,  0.0463,  0.0056]],\n",
       " \n",
       "          [[-0.0123,  0.0189, -0.0169],\n",
       "           [ 0.0103, -0.0232, -0.0129],\n",
       "           [-0.0057, -0.0084, -0.0306]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0015,  0.0044, -0.0139],\n",
       "           [-0.0177, -0.0698,  0.0080],\n",
       "           [-0.0292,  0.0055,  0.0321]],\n",
       " \n",
       "          [[-0.0079,  0.0225,  0.0512],\n",
       "           [-0.0257, -0.0045,  0.0063],\n",
       "           [ 0.0039, -0.0002, -0.0018]],\n",
       " \n",
       "          [[ 0.0159, -0.0224, -0.0139],\n",
       "           [ 0.0246, -0.0010,  0.0081],\n",
       "           [ 0.0284,  0.0011, -0.0008]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0110,  0.0202, -0.0206],\n",
       "           [-0.0311,  0.0125,  0.0053],\n",
       "           [ 0.0063, -0.0088,  0.0085]],\n",
       " \n",
       "          [[ 0.0221,  0.0310, -0.0624],\n",
       "           [-0.0115,  0.0075,  0.0451],\n",
       "           [ 0.0064, -0.0187, -0.0016]],\n",
       " \n",
       "          [[-0.0018, -0.0080, -0.0230],\n",
       "           [ 0.0147, -0.0069, -0.0175],\n",
       "           [-0.0121,  0.0131, -0.0176]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0208, -0.0020,  0.0442],\n",
       "           [ 0.0094,  0.0177, -0.0304],\n",
       "           [-0.0310,  0.0261,  0.0061]],\n",
       " \n",
       "          [[ 0.0452, -0.0137, -0.0220],\n",
       "           [-0.0160,  0.0235, -0.0230],\n",
       "           [-0.0116,  0.0108,  0.0115]],\n",
       " \n",
       "          [[ 0.0157, -0.0041, -0.0635],\n",
       "           [-0.0335,  0.0008,  0.0154],\n",
       "           [-0.0061, -0.0190,  0.0045]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0201, -0.0475, -0.0078],\n",
       "           [-0.0201,  0.0171, -0.0095],\n",
       "           [-0.0353, -0.0101, -0.0265]],\n",
       " \n",
       "          [[-0.0365, -0.0019,  0.0106],\n",
       "           [ 0.0119,  0.0238,  0.0103],\n",
       "           [ 0.0063, -0.0019,  0.0350]],\n",
       " \n",
       "          [[ 0.0314,  0.0196,  0.0173],\n",
       "           [-0.0060, -0.0113,  0.0033],\n",
       "           [-0.0106, -0.0111, -0.0336]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0162,  0.0124,  0.0239],\n",
       "           [ 0.0062,  0.0127,  0.0247],\n",
       "           [-0.0105, -0.0040,  0.0113]],\n",
       " \n",
       "          [[-0.0238, -0.0021,  0.0140],\n",
       "           [ 0.0099, -0.0032,  0.0325],\n",
       "           [ 0.0356, -0.0185, -0.0207]],\n",
       " \n",
       "          [[-0.0065, -0.0038,  0.0048],\n",
       "           [ 0.0129, -0.0058, -0.0119],\n",
       "           [ 0.0134,  0.0309, -0.0240]]],\n",
       " \n",
       " \n",
       "         [[[-0.0417, -0.0072,  0.0017],\n",
       "           [ 0.0029, -0.0167, -0.0260],\n",
       "           [-0.0206, -0.0149,  0.0250]],\n",
       " \n",
       "          [[-0.0220,  0.0087, -0.0204],\n",
       "           [ 0.0236, -0.0047, -0.0148],\n",
       "           [ 0.0272, -0.0358,  0.0236]],\n",
       " \n",
       "          [[ 0.0013, -0.0201, -0.0053],\n",
       "           [ 0.0132,  0.0221, -0.0313],\n",
       "           [ 0.0021,  0.0004, -0.0280]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0153,  0.0051,  0.0544],\n",
       "           [ 0.0350, -0.0115,  0.0050],\n",
       "           [-0.0118,  0.0030, -0.0280]],\n",
       " \n",
       "          [[-0.0319, -0.0274,  0.0217],\n",
       "           [ 0.0030,  0.0033, -0.0017],\n",
       "           [ 0.0282,  0.0266, -0.0076]],\n",
       " \n",
       "          [[-0.0163, -0.0044,  0.0342],\n",
       "           [ 0.0092,  0.0009, -0.0317],\n",
       "           [-0.0090, -0.0204, -0.0090]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0690]],\n",
       " \n",
       "          [[ 0.0465]],\n",
       " \n",
       "          [[ 0.1045]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0889]],\n",
       " \n",
       "          [[-0.1228]],\n",
       " \n",
       "          [[ 0.0321]]],\n",
       " \n",
       " \n",
       "         [[[-0.0317]],\n",
       " \n",
       "          [[-0.0572]],\n",
       " \n",
       "          [[ 0.0861]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0076]],\n",
       " \n",
       "          [[-0.0981]],\n",
       " \n",
       "          [[ 0.0505]]],\n",
       " \n",
       " \n",
       "         [[[-0.1176]],\n",
       " \n",
       "          [[-0.0584]],\n",
       " \n",
       "          [[-0.0089]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0071]],\n",
       " \n",
       "          [[-0.0380]],\n",
       " \n",
       "          [[ 0.0462]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0682]],\n",
       " \n",
       "          [[ 0.0095]],\n",
       " \n",
       "          [[-0.0091]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0039]],\n",
       " \n",
       "          [[-0.1234]],\n",
       " \n",
       "          [[-0.0396]]],\n",
       " \n",
       " \n",
       "         [[[-0.0661]],\n",
       " \n",
       "          [[-0.0768]],\n",
       " \n",
       "          [[-0.0050]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0153]],\n",
       " \n",
       "          [[-0.1095]],\n",
       " \n",
       "          [[-0.0369]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0406]],\n",
       " \n",
       "          [[-0.0755]],\n",
       " \n",
       "          [[-0.0172]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0284]],\n",
       " \n",
       "          [[-0.0101]],\n",
       " \n",
       "          [[ 0.1191]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0265, -0.0200,  0.0212],\n",
       "           [-0.0338,  0.0078, -0.0046],\n",
       "           [-0.0388, -0.0161, -0.0121]],\n",
       " \n",
       "          [[-0.0002,  0.0162,  0.0074],\n",
       "           [-0.0064, -0.0128,  0.0055],\n",
       "           [ 0.0007, -0.0077, -0.0313]],\n",
       " \n",
       "          [[ 0.0127, -0.0031, -0.0116],\n",
       "           [ 0.0180,  0.0317, -0.0079],\n",
       "           [ 0.0344, -0.0164, -0.0228]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0200, -0.0111, -0.0114],\n",
       "           [ 0.0271, -0.0130, -0.0264],\n",
       "           [-0.0214,  0.0211,  0.0037]],\n",
       " \n",
       "          [[ 0.0138, -0.0113, -0.0018],\n",
       "           [-0.0161, -0.0051,  0.0111],\n",
       "           [ 0.0188,  0.0016, -0.0356]],\n",
       " \n",
       "          [[ 0.0099, -0.0292, -0.0043],\n",
       "           [ 0.0238,  0.0113,  0.0136],\n",
       "           [-0.0507,  0.0353, -0.0061]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0282, -0.0027,  0.0073],\n",
       "           [ 0.0173,  0.0323,  0.0113],\n",
       "           [-0.0291,  0.0809, -0.0007]],\n",
       " \n",
       "          [[ 0.0281,  0.0067, -0.0028],\n",
       "           [ 0.0072, -0.0202,  0.0310],\n",
       "           [-0.0018,  0.0109,  0.0032]],\n",
       " \n",
       "          [[ 0.0141, -0.0504,  0.0393],\n",
       "           [ 0.0202,  0.0083, -0.0315],\n",
       "           [ 0.0285,  0.0231, -0.0051]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0283,  0.0049,  0.0040],\n",
       "           [-0.0033,  0.0073,  0.0115],\n",
       "           [-0.0283, -0.0104, -0.0372]],\n",
       " \n",
       "          [[-0.0202, -0.0109,  0.0392],\n",
       "           [ 0.0091,  0.0075,  0.0127],\n",
       "           [ 0.0320,  0.0219, -0.0456]],\n",
       " \n",
       "          [[-0.0312,  0.0024,  0.0004],\n",
       "           [-0.0013, -0.0068,  0.0329],\n",
       "           [ 0.0126,  0.0364,  0.0236]]],\n",
       " \n",
       " \n",
       "         [[[-0.0078, -0.0276, -0.0338],\n",
       "           [-0.0111,  0.0646,  0.0239],\n",
       "           [-0.0013, -0.0055,  0.0076]],\n",
       " \n",
       "          [[-0.0045,  0.0042,  0.0020],\n",
       "           [ 0.0100, -0.0115, -0.0370],\n",
       "           [-0.0274, -0.0124, -0.0476]],\n",
       " \n",
       "          [[ 0.0047, -0.0309,  0.0118],\n",
       "           [ 0.0087,  0.0014,  0.0155],\n",
       "           [-0.0114,  0.0205,  0.0475]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0048, -0.0131, -0.0068],\n",
       "           [-0.0087, -0.0144,  0.0111],\n",
       "           [ 0.0038, -0.0370, -0.0186]],\n",
       " \n",
       "          [[-0.0142, -0.0166,  0.0446],\n",
       "           [ 0.0113, -0.0243,  0.0033],\n",
       "           [ 0.0089,  0.0073,  0.0153]],\n",
       " \n",
       "          [[-0.0228, -0.0174,  0.0127],\n",
       "           [ 0.0449,  0.0299, -0.0228],\n",
       "           [ 0.0148,  0.0004,  0.0014]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0056,  0.0038,  0.0280],\n",
       "           [-0.0287,  0.0067,  0.0114],\n",
       "           [-0.0178, -0.0249, -0.0170]],\n",
       " \n",
       "          [[ 0.0079, -0.0012,  0.0280],\n",
       "           [ 0.0008,  0.0110, -0.0071],\n",
       "           [-0.0030, -0.0065,  0.0289]],\n",
       " \n",
       "          [[-0.0101, -0.0314,  0.0049],\n",
       "           [-0.0008, -0.0243,  0.0131],\n",
       "           [-0.0090,  0.0105, -0.0062]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0183,  0.0299, -0.0210],\n",
       "           [-0.0165, -0.0265, -0.0061],\n",
       "           [-0.0164, -0.0174,  0.0085]],\n",
       " \n",
       "          [[-0.0128,  0.0024, -0.0162],\n",
       "           [ 0.0041, -0.0240,  0.0037],\n",
       "           [-0.0015,  0.0051, -0.0237]],\n",
       " \n",
       "          [[-0.0016,  0.0039, -0.0203],\n",
       "           [ 0.0079, -0.0053,  0.0151],\n",
       "           [-0.0103,  0.0244, -0.0356]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0040,  0.0198,  0.0070],\n",
       "           [ 0.0189, -0.0008, -0.0574],\n",
       "           [ 0.0037,  0.0273,  0.0011]],\n",
       " \n",
       "          [[ 0.0111,  0.0113,  0.0056],\n",
       "           [ 0.0155,  0.0166,  0.0148],\n",
       "           [ 0.0053, -0.0173,  0.0212]],\n",
       " \n",
       "          [[ 0.0052, -0.0240,  0.0185],\n",
       "           [ 0.0073, -0.0042,  0.0131],\n",
       "           [-0.0337, -0.0115,  0.0003]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0177, -0.0122,  0.0137],\n",
       "           [-0.0199, -0.0200,  0.0081],\n",
       "           [-0.0180,  0.0175,  0.0208]],\n",
       " \n",
       "          [[-0.0211,  0.0158, -0.0065],\n",
       "           [ 0.0038,  0.0144, -0.0258],\n",
       "           [ 0.0149,  0.0033,  0.0252]],\n",
       " \n",
       "          [[-0.0041, -0.0021,  0.0216],\n",
       "           [ 0.0020, -0.0155,  0.0384],\n",
       "           [-0.0200,  0.0325,  0.0244]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0159, -0.0149,  0.0159],\n",
       "           [ 0.0403, -0.0088,  0.0033],\n",
       "           [-0.0141,  0.0312,  0.0316]],\n",
       " \n",
       "          [[ 0.0188, -0.0077,  0.0415],\n",
       "           [-0.0044, -0.0105, -0.0017],\n",
       "           [-0.0152, -0.0162, -0.0082]],\n",
       " \n",
       "          [[ 0.0234,  0.0069, -0.0013],\n",
       "           [-0.0248,  0.0146, -0.0033],\n",
       "           [-0.0192, -0.0005,  0.0091]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0438,  0.0332,  0.0110],\n",
       "           [ 0.0142,  0.0092,  0.0036],\n",
       "           [-0.0084,  0.0004,  0.0183]],\n",
       " \n",
       "          [[ 0.0379,  0.0009, -0.0040],\n",
       "           [-0.0136,  0.0036,  0.0106],\n",
       "           [-0.0359,  0.0083,  0.0212]],\n",
       " \n",
       "          [[ 0.0299, -0.0009, -0.0141],\n",
       "           [ 0.0135, -0.0204,  0.0042],\n",
       "           [-0.0094,  0.0074, -0.0508]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0107, -0.0028, -0.0070],\n",
       "           [ 0.0037, -0.0088, -0.0105],\n",
       "           [-0.0138, -0.0142,  0.0397]],\n",
       " \n",
       "          [[-0.0399,  0.0352,  0.0174],\n",
       "           [ 0.0188,  0.0137, -0.0046],\n",
       "           [-0.0019, -0.0129,  0.0134]],\n",
       " \n",
       "          [[ 0.0362, -0.0369, -0.0044],\n",
       "           [-0.0131, -0.0355, -0.0094],\n",
       "           [-0.0128, -0.0093,  0.0164]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0219, -0.0002, -0.0086],\n",
       "           [-0.0190, -0.0303,  0.0033],\n",
       "           [-0.0283,  0.0570, -0.0009]],\n",
       " \n",
       "          [[-0.0209,  0.0207,  0.0119],\n",
       "           [ 0.0128,  0.0041,  0.0401],\n",
       "           [-0.0178,  0.0389, -0.0335]],\n",
       " \n",
       "          [[ 0.0248,  0.0129, -0.0060],\n",
       "           [ 0.0127,  0.0439, -0.0126],\n",
       "           [-0.0187, -0.0188, -0.0118]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0145,  0.0097,  0.0227],\n",
       "           [-0.0087,  0.0023, -0.0110],\n",
       "           [ 0.0231, -0.0143, -0.0205]],\n",
       " \n",
       "          [[ 0.0184, -0.0245, -0.0254],\n",
       "           [ 0.0101, -0.0273,  0.0264],\n",
       "           [ 0.0025, -0.0288,  0.0128]],\n",
       " \n",
       "          [[-0.0006, -0.0069, -0.0110],\n",
       "           [-0.0008,  0.0119,  0.0088],\n",
       "           [-0.0026,  0.0297, -0.0228]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0132,  0.0106,  0.0045],\n",
       "           [ 0.0239, -0.0025,  0.0145],\n",
       "           [ 0.0288,  0.0067, -0.0926]],\n",
       " \n",
       "          [[ 0.0216, -0.0118, -0.0077],\n",
       "           [-0.0104, -0.0122,  0.0076],\n",
       "           [-0.0363,  0.0222,  0.0368]],\n",
       " \n",
       "          [[-0.0404,  0.0126, -0.0038],\n",
       "           [ 0.0311, -0.0008, -0.0340],\n",
       "           [ 0.0145, -0.0059, -0.0357]]],\n",
       " \n",
       " \n",
       "         [[[-0.0212,  0.0146,  0.0130],\n",
       "           [-0.0212, -0.0256,  0.0153],\n",
       "           [ 0.0099,  0.0036,  0.0080]],\n",
       " \n",
       "          [[-0.0047, -0.0060,  0.0010],\n",
       "           [ 0.0150,  0.0025, -0.0118],\n",
       "           [-0.0222,  0.0087, -0.0130]],\n",
       " \n",
       "          [[ 0.0116, -0.0385, -0.0047],\n",
       "           [ 0.0216,  0.0206, -0.0202],\n",
       "           [ 0.0054,  0.0064, -0.0478]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0072, -0.0157, -0.0145],\n",
       "           [ 0.0188, -0.0486,  0.0293],\n",
       "           [ 0.0345,  0.0271, -0.0246]],\n",
       " \n",
       "          [[ 0.0321,  0.0002,  0.0289],\n",
       "           [ 0.0073, -0.0144,  0.0276],\n",
       "           [ 0.0175,  0.0070, -0.0317]],\n",
       " \n",
       "          [[-0.0229, -0.0057,  0.0055],\n",
       "           [-0.0151,  0.0168,  0.0355],\n",
       "           [-0.0114, -0.0089, -0.0265]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0283,  0.0152,  0.0229],\n",
       "           [-0.0270, -0.0131,  0.0128],\n",
       "           [ 0.0099,  0.0071,  0.0199]],\n",
       " \n",
       "          [[-0.0144, -0.0010,  0.0648],\n",
       "           [ 0.0138, -0.0012, -0.0223],\n",
       "           [-0.0156, -0.0076, -0.0326]],\n",
       " \n",
       "          [[-0.0175,  0.0230,  0.0121],\n",
       "           [-0.0054,  0.0004, -0.0205],\n",
       "           [ 0.0060,  0.0098,  0.0482]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0106, -0.0126,  0.0299],\n",
       "           [-0.0214, -0.0281, -0.0088],\n",
       "           [ 0.0011, -0.0008, -0.0003]],\n",
       " \n",
       "          [[ 0.0090,  0.0073, -0.0023],\n",
       "           [ 0.0083, -0.0119,  0.0103],\n",
       "           [-0.0248,  0.0246, -0.0068]],\n",
       " \n",
       "          [[-0.0007, -0.0143,  0.0162],\n",
       "           [-0.0144, -0.0066,  0.0060],\n",
       "           [ 0.0077, -0.0358, -0.0051]]],\n",
       " \n",
       " \n",
       "         [[[-0.0017,  0.0111,  0.0121],\n",
       "           [ 0.0217, -0.0126,  0.0059],\n",
       "           [-0.0231,  0.0169,  0.0225]],\n",
       " \n",
       "          [[-0.0164,  0.0115, -0.0022],\n",
       "           [ 0.0292,  0.0055, -0.0047],\n",
       "           [ 0.0047,  0.0028, -0.0255]],\n",
       " \n",
       "          [[ 0.0178, -0.0035, -0.0131],\n",
       "           [ 0.0010,  0.0038,  0.0082],\n",
       "           [ 0.0048,  0.0071,  0.0152]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0103, -0.0346, -0.0022],\n",
       "           [ 0.0223, -0.0258, -0.0116],\n",
       "           [ 0.0012, -0.0322, -0.0229]],\n",
       " \n",
       "          [[ 0.0133,  0.0137,  0.0141],\n",
       "           [-0.0190,  0.0123, -0.0189],\n",
       "           [ 0.0186, -0.0116, -0.0141]],\n",
       " \n",
       "          [[ 0.0325, -0.0141,  0.0040],\n",
       "           [ 0.0585,  0.0262,  0.0076],\n",
       "           [ 0.0184, -0.0370,  0.0365]]],\n",
       " \n",
       " \n",
       "         [[[-0.0053,  0.0333, -0.0223],\n",
       "           [-0.0339, -0.0109,  0.0009],\n",
       "           [-0.0065, -0.0120,  0.0004]],\n",
       " \n",
       "          [[ 0.0137,  0.0115,  0.0172],\n",
       "           [ 0.0315,  0.0075,  0.0182],\n",
       "           [-0.0172, -0.0027,  0.0166]],\n",
       " \n",
       "          [[-0.0109,  0.0025, -0.0092],\n",
       "           [ 0.0134,  0.0060, -0.0244],\n",
       "           [ 0.0159, -0.0079, -0.0252]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0067,  0.0009,  0.0004],\n",
       "           [-0.0068, -0.0289, -0.0434],\n",
       "           [ 0.0060,  0.0047, -0.0042]],\n",
       " \n",
       "          [[-0.0333,  0.0157, -0.0017],\n",
       "           [-0.0224, -0.0293,  0.0105],\n",
       "           [ 0.0354,  0.0019,  0.0094]],\n",
       " \n",
       "          [[-0.0166,  0.0292,  0.0081],\n",
       "           [-0.0180, -0.0265, -0.0326],\n",
       "           [ 0.0025, -0.0329,  0.0282]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0019,  0.0145,  0.0010,  ..., -0.0164, -0.0347,  0.0097],\n",
       "         [-0.0062,  0.0306,  0.0282,  ..., -0.0231,  0.0225,  0.0127],\n",
       "         [-0.0309, -0.0167, -0.0060,  ..., -0.0063,  0.0226,  0.0016],\n",
       "         ...,\n",
       "         [-0.0266,  0.0070,  0.0138,  ..., -0.0424,  0.0006,  0.0251],\n",
       "         [-0.0246,  0.0364, -0.0184,  ..., -0.0071, -0.0016,  0.0045],\n",
       "         [ 0.0038, -0.0111,  0.0266,  ..., -0.0018, -0.0312, -0.0094]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0358,  0.0440, -0.0062,  0.0382,  0.0358,  0.0441, -0.0276,  0.0292,\n",
       "         -0.0283, -0.0202], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a90e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(net):\n",
    "    '''Init layer parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal(m.weight, mode='fan_out')\n",
    "            if m.bias:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.kaiming_uniform(m.weight, mode=\"fan_in\")\n",
    "            #if m.bias:\n",
    "                #init.kaiming_uniform(m.weight, mode=\"fan_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d0b03e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_674677/1833904545.py:5: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight, mode='fan_out')\n",
      "/tmp/ipykernel_674677/1833904545.py:9: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.weight, 1)\n",
      "/tmp/ipykernel_674677/1833904545.py:10: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(m.bias, 0)\n",
      "/tmp/ipykernel_674677/1833904545.py:12: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
      "  init.kaiming_uniform(m.weight, mode=\"fan_in\")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "init_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14045051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "dev = torch.device('cuda')\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf37950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6601cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an optimizier\n",
    "import torch.optim as optim\n",
    "#optimizer = optim.SGD([x for x in model.parameters() if x.requires_grad], lr = 0.1, momentum=0.9, weight_decay=0.0005)\n",
    "optimizer = optim.Adam([x for x in model.parameters() if x.requires_grad], lr=0.0001)\n",
    "#optimizer = optim.AdamW([x for x in model.parameters() if x.requires_grad], lr=0.001, weight_decay=0.02)\n",
    "# Define a loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#scheduler\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.01, epochs=2, steps_per_epoch=312)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c72f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, loaders, optimizer, criterion, epochs=100, dev=torch.device('cuda')):\n",
    "    try:\n",
    "        net = net.to(dev)\n",
    "        print(net)\n",
    "        # Initialize history\n",
    "        history_loss = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        history_accuracy = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        # Process each epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Initialize epoch variables\n",
    "            sum_loss = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            sum_accuracy = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
    "            # Process each split\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                # Process each batch\n",
    "                for (input, labels) in loaders[split]:\n",
    "                    # Move to CUDA\n",
    "                    input = input.to(dev)\n",
    "                    labels = labels.to(dev)\n",
    "                    # Reset gradients\n",
    "                    optimizer.zero_grad()\n",
    "                    # Compute output\n",
    "                    pred = net(input)\n",
    "                    loss = criterion(pred, labels)\n",
    "                    # Update loss\n",
    "                    sum_loss[split] += loss.item()\n",
    "                    # Check parameter update\n",
    "                    if split == \"train\":\n",
    "                        # Compute gradients\n",
    "                        loss.backward()\n",
    "                        # Optimize\n",
    "                        optimizer.step()\n",
    "                    # Compute accuracy\n",
    "                    _,pred_labels = pred.max(1)\n",
    "                    batch_accuracy = (pred_labels == labels).sum().item()/input.size(0)\n",
    "                    # Update accuracy\n",
    "                    sum_accuracy[split] += batch_accuracy\n",
    "                scheduler.step()\n",
    "            # Compute epoch loss/accuracy\n",
    "            epoch_loss = {split: sum_loss[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            epoch_accuracy = {split: sum_accuracy[split]/len(loaders[split]) for split in [\"train\", \"val\", \"test\"]}\n",
    "            # Update history\n",
    "            for split in [\"train\", \"val\", \"test\"]:\n",
    "                history_loss[split].append(epoch_loss[split])\n",
    "                history_accuracy[split].append(epoch_accuracy[split])\n",
    "            # Print info\n",
    "            print(f\"Epoch {epoch+1}:\",\n",
    "                  f\"TrL={epoch_loss['train']:.4f},\",\n",
    "                  f\"TrA={epoch_accuracy['train']:.4f},\",\n",
    "                  f\"VL={epoch_loss['val']:.4f},\",\n",
    "                  f\"VA={epoch_accuracy['val']:.4f},\",\n",
    "                  f\"TeL={epoch_loss['test']:.4f},\",\n",
    "                  f\"TeA={epoch_accuracy['test']:.4f},\",\n",
    "                  f\"LR={optimizer.param_groups[0]['lr']:.5f},\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    finally:\n",
    "        # Plot loss\n",
    "        plt.title(\"Loss\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_loss[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        # Plot accuracy\n",
    "        plt.title(\"Accuracy\")\n",
    "        for split in [\"train\", \"val\", \"test\"]:\n",
    "            plt.plot(history_accuracy[split], label=split)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Define dictionary of loaders\n",
    "loaders = {\"train\": train_loader,\n",
    "           \"val\": val_loader,\n",
    "           \"test\": test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b35e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Epoch 1: TrL=1.7293, TrA=0.3920, VL=1.3727, VA=0.5156, TeL=1.3797, TeA=0.4978, LR=0.00041,\n",
      "Epoch 2: TrL=1.3271, TrA=0.5184, VL=1.1849, VA=0.5782, TeL=1.2237, TeA=0.5558, LR=0.00042,\n",
      "Epoch 3: TrL=1.1599, TrA=0.5862, VL=1.0507, VA=0.6253, TeL=1.0612, TeA=0.6177, LR=0.00046,\n",
      "Epoch 4: TrL=1.0369, TrA=0.6318, VL=0.9702, VA=0.6579, TeL=0.9952, TeA=0.6471, LR=0.00050,\n",
      "Epoch 5: TrL=0.9686, TrA=0.6566, VL=0.9310, VA=0.6713, TeL=0.9610, TeA=0.6584, LR=0.00055,\n",
      "Epoch 6: TrL=0.8932, TrA=0.6870, VL=0.8917, VA=0.6839, TeL=0.9173, TeA=0.6766, LR=0.00062,\n",
      "Epoch 7: TrL=0.8484, TrA=0.7015, VL=0.8443, VA=0.6972, TeL=0.8621, TeA=0.7007, LR=0.00070,\n",
      "Epoch 8: TrL=0.8096, TrA=0.7128, VL=0.7916, VA=0.7303, TeL=0.8217, TeA=0.7138, LR=0.00079,\n",
      "Epoch 9: TrL=0.7721, TrA=0.7296, VL=0.7784, VA=0.7323, TeL=0.8028, TeA=0.7213, LR=0.00089,\n",
      "Epoch 10: TrL=0.7386, TrA=0.7406, VL=0.7905, VA=0.7301, TeL=0.7996, TeA=0.7301, LR=0.00100,\n",
      "Epoch 11: TrL=0.7137, TrA=0.7488, VL=0.7512, VA=0.7399, TeL=0.7771, TeA=0.7336, LR=0.00112,\n",
      "Epoch 12: TrL=0.6925, TrA=0.7581, VL=0.7504, VA=0.7413, TeL=0.7805, TeA=0.7329, LR=0.00126,\n",
      "Epoch 13: TrL=0.6792, TrA=0.7631, VL=0.7439, VA=0.7449, TeL=0.7665, TeA=0.7357, LR=0.00140,\n",
      "Epoch 14: TrL=0.6536, TrA=0.7734, VL=0.7272, VA=0.7478, TeL=0.7423, TeA=0.7471, LR=0.00156,\n",
      "Epoch 15: TrL=0.6439, TrA=0.7750, VL=0.7501, VA=0.7463, TeL=0.7658, TeA=0.7394, LR=0.00172,\n",
      "Epoch 16: TrL=0.6110, TrA=0.7874, VL=0.7200, VA=0.7632, TeL=0.7414, TeA=0.7516, LR=0.00189,\n",
      "Epoch 17: TrL=0.6137, TrA=0.7870, VL=0.6598, VA=0.7743, TeL=0.6781, TeA=0.7695, LR=0.00207,\n",
      "Epoch 18: TrL=0.5906, TrA=0.7939, VL=0.7030, VA=0.7673, TeL=0.7406, TeA=0.7569, LR=0.00226,\n",
      "Epoch 19: TrL=0.5724, TrA=0.8007, VL=0.6840, VA=0.7674, TeL=0.7174, TeA=0.7611, LR=0.00245,\n",
      "Epoch 20: TrL=0.5710, TrA=0.8002, VL=0.7118, VA=0.7637, TeL=0.7411, TeA=0.7574, LR=0.00266,\n",
      "Epoch 21: TrL=0.5700, TrA=0.8030, VL=0.6588, VA=0.7825, TeL=0.6788, TeA=0.7666, LR=0.00287,\n",
      "Epoch 22: TrL=0.5442, TrA=0.8105, VL=0.6854, VA=0.7653, TeL=0.7103, TeA=0.7598, LR=0.00308,\n",
      "Epoch 23: TrL=0.6093, TrA=0.7934, VL=0.7140, VA=0.7623, TeL=0.7295, TeA=0.7651, LR=0.00330,\n",
      "Epoch 24: TrL=0.6658, TrA=0.7754, VL=0.8749, VA=0.7018, TeL=0.9066, TeA=0.7010, LR=0.00353,\n",
      "Epoch 25: TrL=0.6069, TrA=0.7917, VL=0.6351, VA=0.7885, TeL=0.6530, TeA=0.7856, LR=0.00376,\n",
      "Epoch 26: TrL=0.4959, TrA=0.8284, VL=0.6455, VA=0.7822, TeL=0.6610, TeA=0.7839, LR=0.00399,\n",
      "Epoch 27: TrL=0.4832, TrA=0.8336, VL=0.6365, VA=0.7894, TeL=0.6733, TeA=0.7788, LR=0.00423,\n",
      "Epoch 28: TrL=0.4692, TrA=0.8368, VL=0.6122, VA=0.7961, TeL=0.6468, TeA=0.7980, LR=0.00447,\n",
      "Epoch 29: TrL=0.4537, TrA=0.8455, VL=0.6427, VA=0.7912, TeL=0.6555, TeA=0.7944, LR=0.00471,\n",
      "Epoch 30: TrL=0.6363, TrA=0.7866, VL=0.7124, VA=0.7611, TeL=0.7046, TeA=0.7606, LR=0.00495,\n",
      "Epoch 31: TrL=0.5631, TrA=0.8078, VL=0.6435, VA=0.7858, TeL=0.6715, TeA=0.7815, LR=0.00519,\n",
      "Epoch 32: TrL=0.4476, TrA=0.8459, VL=0.5915, VA=0.8065, TeL=0.6146, TeA=0.8020, LR=0.00543,\n",
      "Epoch 33: TrL=0.4298, TrA=0.8515, VL=0.6373, VA=0.7939, TeL=0.6669, TeA=0.7824, LR=0.00568,\n",
      "Epoch 34: TrL=0.4208, TrA=0.8553, VL=0.6617, VA=0.7887, TeL=0.6730, TeA=0.7880, LR=0.00592,\n",
      "Epoch 35: TrL=0.4108, TrA=0.8590, VL=0.6421, VA=0.7989, TeL=0.6683, TeA=0.7918, LR=0.00616,\n",
      "Epoch 36: TrL=0.5506, TrA=0.8166, VL=0.7873, VA=0.7358, TeL=0.8159, TeA=0.7301, LR=0.00639,\n",
      "Epoch 37: TrL=0.4692, TrA=0.8396, VL=0.6280, VA=0.8013, TeL=0.6529, TeA=0.7923, LR=0.00663,\n",
      "Epoch 38: TrL=0.3980, TrA=0.8615, VL=0.6343, VA=0.8007, TeL=0.6412, TeA=0.8007, LR=0.00686,\n",
      "Epoch 39: TrL=0.3812, TrA=0.8680, VL=0.6385, VA=0.8036, TeL=0.6668, TeA=0.8004, LR=0.00708,\n",
      "Epoch 40: TrL=0.3768, TrA=0.8727, VL=0.6188, VA=0.8018, TeL=0.6403, TeA=0.8022, LR=0.00730,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: TrL=0.3874, TrA=0.8689, VL=0.6137, VA=0.8092, TeL=0.6415, TeA=0.8017, LR=0.00752,\n",
      "Epoch 42: TrL=0.3672, TrA=0.8731, VL=0.6173, VA=0.8072, TeL=0.6324, TeA=0.7992, LR=0.00773,\n",
      "Epoch 43: TrL=0.3728, TrA=0.8728, VL=0.6493, VA=0.7966, TeL=0.6674, TeA=0.7915, LR=0.00793,\n",
      "Epoch 44: TrL=0.3571, TrA=0.8793, VL=0.6213, VA=0.8063, TeL=0.6573, TeA=0.7950, LR=0.00813,\n",
      "Epoch 45: TrL=0.3690, TrA=0.8748, VL=0.6628, VA=0.7881, TeL=0.6702, TeA=0.7855, LR=0.00832,\n",
      "Epoch 46: TrL=0.3741, TrA=0.8715, VL=0.6160, VA=0.8047, TeL=0.6370, TeA=0.8018, LR=0.00850,\n",
      "Epoch 47: TrL=0.3358, TrA=0.8864, VL=0.5977, VA=0.8144, TeL=0.6111, TeA=0.8099, LR=0.00867,\n",
      "Epoch 48: TrL=0.3314, TrA=0.8860, VL=0.6500, VA=0.8040, TeL=0.6681, TeA=0.8055, LR=0.00883,\n",
      "Epoch 49: TrL=0.3266, TrA=0.8876, VL=0.6408, VA=0.8091, TeL=0.6510, TeA=0.8076, LR=0.00899,\n",
      "Epoch 50: TrL=0.3113, TrA=0.8952, VL=0.5994, VA=0.8116, TeL=0.6344, TeA=0.8126, LR=0.00913,\n",
      "Epoch 51: TrL=0.3192, TrA=0.8924, VL=0.6295, VA=0.8096, TeL=0.6506, TeA=0.8077, LR=0.00927,\n",
      "Epoch 52: TrL=0.3092, TrA=0.8955, VL=0.6116, VA=0.8122, TeL=0.6296, TeA=0.8074, LR=0.00939,\n",
      "Epoch 53: TrL=0.3046, TrA=0.8945, VL=0.6140, VA=0.8151, TeL=0.6617, TeA=0.8049, LR=0.00950,\n",
      "Epoch 54: TrL=0.2900, TrA=0.9013, VL=0.6377, VA=0.8108, TeL=0.6566, TeA=0.8073, LR=0.00961,\n",
      "Epoch 55: TrL=0.3224, TrA=0.8902, VL=0.7222, VA=0.7828, TeL=0.7090, TeA=0.7809, LR=0.00970,\n",
      "Epoch 56: TrL=0.3044, TrA=0.8965, VL=0.6234, VA=0.8135, TeL=0.6474, TeA=0.8086, LR=0.00978,\n",
      "Epoch 57: TrL=0.2774, TrA=0.9049, VL=0.6509, VA=0.8142, TeL=0.6750, TeA=0.8093, LR=0.00984,\n",
      "Epoch 58: TrL=0.2796, TrA=0.9045, VL=0.6627, VA=0.8132, TeL=0.6907, TeA=0.8028, LR=0.00990,\n",
      "Epoch 59: TrL=0.4530, TrA=0.8514, VL=0.6344, VA=0.8009, TeL=0.6466, TeA=0.7981, LR=0.00994,\n",
      "Epoch 60: TrL=0.3748, TrA=0.8723, VL=0.6288, VA=0.8158, TeL=0.6500, TeA=0.8129, LR=0.00997,\n",
      "Epoch 61: TrL=0.2740, TrA=0.9078, VL=0.6002, VA=0.8227, TeL=0.6198, TeA=0.8153, LR=0.00999,\n",
      "Epoch 62: TrL=0.2693, TrA=0.9090, VL=0.6106, VA=0.8188, TeL=0.6425, TeA=0.8094, LR=0.01000,\n",
      "Epoch 63: TrL=0.2462, TrA=0.9157, VL=0.6095, VA=0.8259, TeL=0.6641, TeA=0.8170, LR=0.01000,\n",
      "Epoch 64: TrL=0.2421, TrA=0.9177, VL=0.6518, VA=0.8186, TeL=0.6966, TeA=0.8053, LR=0.01000,\n",
      "Epoch 65: TrL=0.2422, TrA=0.9174, VL=0.6674, VA=0.8164, TeL=0.6966, TeA=0.8120, LR=0.00999,\n",
      "Epoch 66: TrL=0.2446, TrA=0.9161, VL=0.6085, VA=0.8282, TeL=0.6547, TeA=0.8189, LR=0.00998,\n",
      "Epoch 67: TrL=0.2308, TrA=0.9220, VL=0.6202, VA=0.8298, TeL=0.6403, TeA=0.8237, LR=0.00997,\n",
      "Epoch 68: TrL=0.2278, TrA=0.9222, VL=0.6353, VA=0.8228, TeL=0.6625, TeA=0.8205, LR=0.00996,\n",
      "Epoch 69: TrL=0.2289, TrA=0.9217, VL=0.6108, VA=0.8252, TeL=0.6526, TeA=0.8184, LR=0.00994,\n",
      "Epoch 70: TrL=0.2215, TrA=0.9235, VL=0.6552, VA=0.8267, TeL=0.6793, TeA=0.8175, LR=0.00993,\n",
      "Epoch 71: TrL=0.2160, TrA=0.9270, VL=0.5972, VA=0.8291, TeL=0.6441, TeA=0.8208, LR=0.00991,\n",
      "Epoch 72: TrL=0.2168, TrA=0.9266, VL=0.6321, VA=0.8277, TeL=0.6469, TeA=0.8216, LR=0.00989,\n",
      "Epoch 73: TrL=0.2062, TrA=0.9303, VL=0.6652, VA=0.8202, TeL=0.6713, TeA=0.8197, LR=0.00986,\n",
      "Epoch 74: TrL=0.2095, TrA=0.9291, VL=0.6418, VA=0.8237, TeL=0.6509, TeA=0.8225, LR=0.00984,\n",
      "Epoch 75: TrL=0.2026, TrA=0.9319, VL=0.6382, VA=0.8260, TeL=0.6821, TeA=0.8191, LR=0.00981,\n",
      "Epoch 76: TrL=0.2174, TrA=0.9255, VL=0.6348, VA=0.8294, TeL=0.6728, TeA=0.8214, LR=0.00978,\n",
      "Epoch 77: TrL=0.1975, TrA=0.9336, VL=0.6239, VA=0.8301, TeL=0.6774, TeA=0.8203, LR=0.00974,\n",
      "Epoch 78: TrL=0.1945, TrA=0.9333, VL=0.6281, VA=0.8329, TeL=0.6939, TeA=0.8242, LR=0.00971,\n",
      "Epoch 79: TrL=0.1938, TrA=0.9336, VL=0.6417, VA=0.8227, TeL=0.6603, TeA=0.8230, LR=0.00967,\n",
      "Epoch 80: TrL=0.1921, TrA=0.9348, VL=0.6217, VA=0.8325, TeL=0.6799, TeA=0.8204, LR=0.00963,\n",
      "Epoch 81: TrL=0.1823, TrA=0.9380, VL=0.6351, VA=0.8284, TeL=0.6604, TeA=0.8250, LR=0.00959,\n",
      "Epoch 82: TrL=0.1789, TrA=0.9402, VL=0.6233, VA=0.8266, TeL=0.6772, TeA=0.8245, LR=0.00954,\n",
      "Epoch 83: TrL=0.1753, TrA=0.9401, VL=0.6499, VA=0.8338, TeL=0.6808, TeA=0.8274, LR=0.00950,\n",
      "Epoch 84: TrL=0.1781, TrA=0.9397, VL=0.6516, VA=0.8304, TeL=0.6710, TeA=0.8316, LR=0.00945,\n",
      "Epoch 85: TrL=0.1719, TrA=0.9406, VL=0.6750, VA=0.8253, TeL=0.6822, TeA=0.8231, LR=0.00940,\n",
      "Epoch 86: TrL=0.1671, TrA=0.9434, VL=0.6830, VA=0.8263, TeL=0.7103, TeA=0.8246, LR=0.00935,\n",
      "Epoch 87: TrL=0.1665, TrA=0.9430, VL=0.6519, VA=0.8310, TeL=0.6789, TeA=0.8259, LR=0.00929,\n",
      "Epoch 88: TrL=0.1613, TrA=0.9461, VL=0.6710, VA=0.8316, TeL=0.6941, TeA=0.8280, LR=0.00924,\n",
      "Epoch 89: TrL=0.1573, TrA=0.9451, VL=0.6472, VA=0.8378, TeL=0.6790, TeA=0.8340, LR=0.00918,\n",
      "Epoch 90: TrL=0.1593, TrA=0.9463, VL=0.6720, VA=0.8285, TeL=0.7114, TeA=0.8262, LR=0.00912,\n",
      "Epoch 91: TrL=0.1933, TrA=0.9357, VL=0.7343, VA=0.8016, TeL=0.7612, TeA=0.7923, LR=0.00906,\n",
      "Epoch 92: TrL=0.1702, TrA=0.9423, VL=0.6299, VA=0.8382, TeL=0.6912, TeA=0.8336, LR=0.00899,\n",
      "Epoch 93: TrL=0.1525, TrA=0.9463, VL=0.6070, VA=0.8358, TeL=0.6414, TeA=0.8357, LR=0.00893,\n",
      "Epoch 94: TrL=0.1460, TrA=0.9512, VL=0.6932, VA=0.8287, TeL=0.6978, TeA=0.8266, LR=0.00886,\n",
      "Epoch 95: TrL=0.1451, TrA=0.9489, VL=0.6674, VA=0.8393, TeL=0.7081, TeA=0.8332, LR=0.00879,\n",
      "Epoch 96: TrL=0.1423, TrA=0.9520, VL=0.6749, VA=0.8339, TeL=0.7035, TeA=0.8308, LR=0.00872,\n",
      "Epoch 97: TrL=0.1424, TrA=0.9513, VL=0.7088, VA=0.8310, TeL=0.7393, TeA=0.8306, LR=0.00865,\n",
      "Epoch 98: TrL=0.1385, TrA=0.9535, VL=0.6973, VA=0.8365, TeL=0.7179, TeA=0.8322, LR=0.00857,\n",
      "Epoch 99: TrL=0.1387, TrA=0.9527, VL=0.7057, VA=0.8358, TeL=0.7226, TeA=0.8342, LR=0.00849,\n",
      "Epoch 100: TrL=0.1316, TrA=0.9555, VL=0.7041, VA=0.8323, TeL=0.7043, TeA=0.8305, LR=0.00842,\n",
      "Epoch 101: TrL=0.1380, TrA=0.9529, VL=0.6576, VA=0.8390, TeL=0.6962, TeA=0.8307, LR=0.00834,\n",
      "Epoch 102: TrL=0.1328, TrA=0.9560, VL=0.6421, VA=0.8363, TeL=0.6685, TeA=0.8382, LR=0.00826,\n",
      "Epoch 103: TrL=0.1274, TrA=0.9558, VL=0.7251, VA=0.8366, TeL=0.7517, TeA=0.8331, LR=0.00817,\n",
      "Epoch 104: TrL=0.1263, TrA=0.9571, VL=0.6566, VA=0.8387, TeL=0.6832, TeA=0.8353, LR=0.00809,\n",
      "Epoch 105: TrL=0.1245, TrA=0.9566, VL=0.6675, VA=0.8406, TeL=0.7145, TeA=0.8345, LR=0.00800,\n",
      "Epoch 106: TrL=0.1195, TrA=0.9592, VL=0.6703, VA=0.8391, TeL=0.7151, TeA=0.8331, LR=0.00792,\n",
      "Epoch 107: TrL=0.1152, TrA=0.9613, VL=0.6818, VA=0.8427, TeL=0.7378, TeA=0.8334, LR=0.00783,\n",
      "Epoch 108: TrL=0.1188, TrA=0.9578, VL=0.6723, VA=0.8456, TeL=0.7288, TeA=0.8356, LR=0.00774,\n",
      "Epoch 109: TrL=0.1188, TrA=0.9598, VL=0.7094, VA=0.8394, TeL=0.7326, TeA=0.8320, LR=0.00765,\n",
      "Epoch 110: TrL=0.1139, TrA=0.9610, VL=0.6669, VA=0.8432, TeL=0.7226, TeA=0.8299, LR=0.00756,\n",
      "Epoch 111: TrL=0.1088, TrA=0.9633, VL=0.6804, VA=0.8417, TeL=0.7256, TeA=0.8359, LR=0.00746,\n",
      "Epoch 112: TrL=0.1080, TrA=0.9630, VL=0.7238, VA=0.8399, TeL=0.7338, TeA=0.8356, LR=0.00737,\n",
      "Epoch 113: TrL=0.1049, TrA=0.9636, VL=0.7024, VA=0.8447, TeL=0.7425, TeA=0.8352, LR=0.00727,\n",
      "Epoch 114: TrL=0.1054, TrA=0.9634, VL=0.6707, VA=0.8438, TeL=0.7376, TeA=0.8372, LR=0.00718,\n",
      "Epoch 115: TrL=0.1068, TrA=0.9645, VL=0.6819, VA=0.8468, TeL=0.7199, TeA=0.8397, LR=0.00708,\n",
      "Epoch 116: TrL=0.1026, TrA=0.9647, VL=0.6837, VA=0.8421, TeL=0.7213, TeA=0.8331, LR=0.00698,\n",
      "Epoch 117: TrL=0.1003, TrA=0.9662, VL=0.7180, VA=0.8401, TeL=0.7470, TeA=0.8355, LR=0.00688,\n",
      "Epoch 118: TrL=0.1005, TrA=0.9650, VL=0.6904, VA=0.8399, TeL=0.7345, TeA=0.8343, LR=0.00678,\n",
      "Epoch 119: TrL=0.0970, TrA=0.9664, VL=0.6824, VA=0.8485, TeL=0.7238, TeA=0.8419, LR=0.00668,\n",
      "Epoch 120: TrL=0.0960, TrA=0.9667, VL=0.7151, VA=0.8465, TeL=0.7435, TeA=0.8405, LR=0.00658,\n",
      "Epoch 121: TrL=0.0928, TrA=0.9681, VL=0.7206, VA=0.8438, TeL=0.7573, TeA=0.8388, LR=0.00647,\n",
      "Epoch 122: TrL=0.0913, TrA=0.9685, VL=0.6991, VA=0.8484, TeL=0.7357, TeA=0.8440, LR=0.00637,\n",
      "Epoch 123: TrL=0.0876, TrA=0.9699, VL=0.7023, VA=0.8461, TeL=0.7366, TeA=0.8447, LR=0.00627,\n",
      "Epoch 124: TrL=0.0877, TrA=0.9696, VL=0.7055, VA=0.8445, TeL=0.7524, TeA=0.8381, LR=0.00616,\n",
      "Epoch 125: TrL=0.0860, TrA=0.9708, VL=0.7328, VA=0.8440, TeL=0.7486, TeA=0.8388, LR=0.00606,\n",
      "Epoch 126: TrL=0.0847, TrA=0.9704, VL=0.7313, VA=0.8481, TeL=0.7493, TeA=0.8384, LR=0.00595,\n",
      "Epoch 127: TrL=0.0809, TrA=0.9724, VL=0.6832, VA=0.8499, TeL=0.7152, TeA=0.8439, LR=0.00584,\n",
      "Epoch 128: TrL=0.0827, TrA=0.9719, VL=0.7223, VA=0.8441, TeL=0.7517, TeA=0.8436, LR=0.00574,\n",
      "Epoch 129: TrL=0.0795, TrA=0.9741, VL=0.7313, VA=0.8470, TeL=0.7760, TeA=0.8415, LR=0.00563,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130: TrL=0.0770, TrA=0.9735, VL=0.7677, VA=0.8488, TeL=0.8028, TeA=0.8438, LR=0.00552,\n",
      "Epoch 131: TrL=0.0748, TrA=0.9747, VL=0.7532, VA=0.8446, TeL=0.8124, TeA=0.8391, LR=0.00542,\n",
      "Epoch 132: TrL=0.0715, TrA=0.9754, VL=0.7539, VA=0.8478, TeL=0.7701, TeA=0.8425, LR=0.00531,\n",
      "Epoch 133: TrL=0.0734, TrA=0.9751, VL=0.7276, VA=0.8458, TeL=0.7626, TeA=0.8469, LR=0.00520,\n",
      "Epoch 134: TrL=0.0752, TrA=0.9741, VL=0.7246, VA=0.8495, TeL=0.7710, TeA=0.8448, LR=0.00509,\n",
      "Epoch 135: TrL=0.0685, TrA=0.9758, VL=0.7707, VA=0.8422, TeL=0.8011, TeA=0.8424, LR=0.00499,\n",
      "Epoch 136: TrL=0.0676, TrA=0.9764, VL=0.7182, VA=0.8495, TeL=0.7522, TeA=0.8495, LR=0.00488,\n",
      "Epoch 137: TrL=0.0665, TrA=0.9770, VL=0.7817, VA=0.8456, TeL=0.7946, TeA=0.8420, LR=0.00477,\n",
      "Epoch 138: TrL=0.0635, TrA=0.9780, VL=0.7517, VA=0.8465, TeL=0.7919, TeA=0.8455, LR=0.00466,\n",
      "Epoch 139: TrL=0.0610, TrA=0.9786, VL=0.7600, VA=0.8497, TeL=0.7752, TeA=0.8496, LR=0.00455,\n",
      "Epoch 140: TrL=0.0592, TrA=0.9794, VL=0.7435, VA=0.8478, TeL=0.8008, TeA=0.8473, LR=0.00445,\n",
      "Epoch 141: TrL=0.0604, TrA=0.9791, VL=0.7699, VA=0.8494, TeL=0.7937, TeA=0.8468, LR=0.00434,\n",
      "Epoch 142: TrL=0.0553, TrA=0.9814, VL=0.7640, VA=0.8525, TeL=0.8201, TeA=0.8444, LR=0.00423,\n",
      "Epoch 143: TrL=0.0567, TrA=0.9805, VL=0.7797, VA=0.8463, TeL=0.8300, TeA=0.8422, LR=0.00413,\n",
      "Epoch 144: TrL=0.0550, TrA=0.9815, VL=0.7567, VA=0.8497, TeL=0.8050, TeA=0.8444, LR=0.00402,\n",
      "Epoch 145: TrL=0.0590, TrA=0.9796, VL=0.7766, VA=0.8527, TeL=0.8072, TeA=0.8453, LR=0.00392,\n",
      "Epoch 146: TrL=0.0541, TrA=0.9816, VL=0.7705, VA=0.8489, TeL=0.8014, TeA=0.8463, LR=0.00381,\n",
      "Epoch 147: TrL=0.0523, TrA=0.9819, VL=0.7717, VA=0.8518, TeL=0.7911, TeA=0.8445, LR=0.00371,\n",
      "Epoch 148: TrL=0.0489, TrA=0.9829, VL=0.7612, VA=0.8508, TeL=0.7835, TeA=0.8493, LR=0.00360,\n",
      "Epoch 149: TrL=0.0481, TrA=0.9835, VL=0.7560, VA=0.8516, TeL=0.7689, TeA=0.8517, LR=0.00350,\n",
      "Epoch 150: TrL=0.0460, TrA=0.9844, VL=0.8039, VA=0.8497, TeL=0.7961, TeA=0.8506, LR=0.00340,\n",
      "Epoch 151: TrL=0.0485, TrA=0.9829, VL=0.8024, VA=0.8478, TeL=0.8144, TeA=0.8463, LR=0.00329,\n",
      "Epoch 152: TrL=0.0433, TrA=0.9852, VL=0.7735, VA=0.8543, TeL=0.7952, TeA=0.8550, LR=0.00319,\n",
      "Epoch 153: TrL=0.0455, TrA=0.9841, VL=0.7579, VA=0.8567, TeL=0.7928, TeA=0.8521, LR=0.00309,\n",
      "Epoch 154: TrL=0.0446, TrA=0.9843, VL=0.7769, VA=0.8539, TeL=0.8181, TeA=0.8484, LR=0.00299,\n",
      "Epoch 155: TrL=0.0460, TrA=0.9848, VL=0.7810, VA=0.8524, TeL=0.7860, TeA=0.8506, LR=0.00290,\n",
      "Epoch 156: TrL=0.0397, TrA=0.9862, VL=0.7868, VA=0.8548, TeL=0.8223, TeA=0.8496, LR=0.00280,\n",
      "Epoch 157: TrL=0.0401, TrA=0.9862, VL=0.8298, VA=0.8508, TeL=0.8301, TeA=0.8517, LR=0.00270,\n",
      "Epoch 158: TrL=0.0390, TrA=0.9861, VL=0.8263, VA=0.8530, TeL=0.8479, TeA=0.8499, LR=0.00261,\n",
      "Epoch 159: TrL=0.0399, TrA=0.9863, VL=0.8092, VA=0.8480, TeL=0.8386, TeA=0.8486, LR=0.00251,\n",
      "Epoch 160: TrL=0.0362, TrA=0.9871, VL=0.8377, VA=0.8497, TeL=0.8578, TeA=0.8476, LR=0.00242,\n",
      "Epoch 161: TrL=0.0370, TrA=0.9879, VL=0.7966, VA=0.8524, TeL=0.8356, TeA=0.8500, LR=0.00233,\n",
      "Epoch 162: TrL=0.0364, TrA=0.9875, VL=0.7781, VA=0.8575, TeL=0.8228, TeA=0.8505, LR=0.00224,\n",
      "Epoch 163: TrL=0.0311, TrA=0.9888, VL=0.8385, VA=0.8528, TeL=0.8650, TeA=0.8523, LR=0.00215,\n",
      "Epoch 164: TrL=0.0331, TrA=0.9890, VL=0.8487, VA=0.8500, TeL=0.8669, TeA=0.8520, LR=0.00206,\n",
      "Epoch 165: TrL=0.0302, TrA=0.9897, VL=0.8619, VA=0.8491, TeL=0.8657, TeA=0.8524, LR=0.00197,\n",
      "Epoch 166: TrL=0.0274, TrA=0.9909, VL=0.8725, VA=0.8525, TeL=0.8906, TeA=0.8529, LR=0.00189,\n",
      "Epoch 167: TrL=0.0300, TrA=0.9895, VL=0.8526, VA=0.8540, TeL=0.8561, TeA=0.8534, LR=0.00180,\n",
      "Epoch 168: TrL=0.0288, TrA=0.9901, VL=0.8464, VA=0.8562, TeL=0.8869, TeA=0.8531, LR=0.00172,\n",
      "Epoch 169: TrL=0.0284, TrA=0.9905, VL=0.8750, VA=0.8539, TeL=0.8968, TeA=0.8506, LR=0.00164,\n",
      "Epoch 170: TrL=0.0299, TrA=0.9901, VL=0.8523, VA=0.8516, TeL=0.8762, TeA=0.8535, LR=0.00156,\n",
      "Epoch 171: TrL=0.0287, TrA=0.9903, VL=0.8592, VA=0.8562, TeL=0.8663, TeA=0.8516, LR=0.00148,\n",
      "Epoch 172: TrL=0.0279, TrA=0.9906, VL=0.8316, VA=0.8567, TeL=0.8655, TeA=0.8513, LR=0.00141,\n",
      "Epoch 173: TrL=0.0258, TrA=0.9911, VL=0.8608, VA=0.8539, TeL=0.9014, TeA=0.8505, LR=0.00133,\n",
      "Epoch 174: TrL=0.0253, TrA=0.9911, VL=0.8445, VA=0.8559, TeL=0.8782, TeA=0.8525, LR=0.00126,\n",
      "Epoch 175: TrL=0.0223, TrA=0.9919, VL=0.8610, VA=0.8558, TeL=0.8745, TeA=0.8545, LR=0.00119,\n",
      "Epoch 176: TrL=0.0225, TrA=0.9925, VL=0.8941, VA=0.8533, TeL=0.9089, TeA=0.8532, LR=0.00112,\n",
      "Epoch 177: TrL=0.0233, TrA=0.9916, VL=0.8576, VA=0.8585, TeL=0.8842, TeA=0.8533, LR=0.00106,\n",
      "Epoch 178: TrL=0.0230, TrA=0.9923, VL=0.8685, VA=0.8576, TeL=0.8956, TeA=0.8548, LR=0.00099,\n",
      "Epoch 179: TrL=0.0216, TrA=0.9924, VL=0.8813, VA=0.8574, TeL=0.8965, TeA=0.8566, LR=0.00093,\n",
      "Epoch 180: TrL=0.0200, TrA=0.9927, VL=0.8932, VA=0.8583, TeL=0.9128, TeA=0.8553, LR=0.00086,\n",
      "Epoch 181: TrL=0.0222, TrA=0.9923, VL=0.8749, VA=0.8616, TeL=0.9101, TeA=0.8547, LR=0.00081,\n",
      "Epoch 182: TrL=0.0196, TrA=0.9932, VL=0.8727, VA=0.8578, TeL=0.9066, TeA=0.8572, LR=0.00075,\n",
      "Epoch 183: TrL=0.0187, TrA=0.9937, VL=0.8984, VA=0.8558, TeL=0.9313, TeA=0.8548, LR=0.00069,\n",
      "Epoch 184: TrL=0.0198, TrA=0.9934, VL=0.8911, VA=0.8576, TeL=0.9191, TeA=0.8553, LR=0.00064,\n",
      "Epoch 185: TrL=0.0196, TrA=0.9930, VL=0.8814, VA=0.8589, TeL=0.9275, TeA=0.8549, LR=0.00059,\n",
      "Epoch 186: TrL=0.0189, TrA=0.9933, VL=0.8818, VA=0.8587, TeL=0.9326, TeA=0.8545, LR=0.00054,\n",
      "Epoch 187: TrL=0.0172, TrA=0.9941, VL=0.9016, VA=0.8595, TeL=0.9442, TeA=0.8540, LR=0.00049,\n",
      "Epoch 188: TrL=0.0183, TrA=0.9942, VL=0.9040, VA=0.8574, TeL=0.9336, TeA=0.8546, LR=0.00044,\n",
      "Epoch 189: TrL=0.0177, TrA=0.9937, VL=0.8859, VA=0.8593, TeL=0.9335, TeA=0.8558, LR=0.00040,\n",
      "Epoch 190: TrL=0.0190, TrA=0.9940, VL=0.9109, VA=0.8580, TeL=0.9374, TeA=0.8536, LR=0.00036,\n",
      "Epoch 191: TrL=0.0188, TrA=0.9939, VL=0.8965, VA=0.8598, TeL=0.9353, TeA=0.8547, LR=0.00032,\n",
      "Epoch 192: TrL=0.0176, TrA=0.9934, VL=0.8853, VA=0.8591, TeL=0.9325, TeA=0.8549, LR=0.00028,\n",
      "Epoch 193: TrL=0.0178, TrA=0.9941, VL=0.8858, VA=0.8589, TeL=0.9328, TeA=0.8563, LR=0.00025,\n",
      "Epoch 194: TrL=0.0153, TrA=0.9947, VL=0.8979, VA=0.8596, TeL=0.9340, TeA=0.8569, LR=0.00022,\n",
      "Epoch 195: TrL=0.0163, TrA=0.9946, VL=0.8925, VA=0.8580, TeL=0.9340, TeA=0.8558, LR=0.00019,\n",
      "Epoch 196: TrL=0.0165, TrA=0.9941, VL=0.9205, VA=0.8581, TeL=0.9350, TeA=0.8549, LR=0.00016,\n",
      "Epoch 197: TrL=0.0166, TrA=0.9941, VL=0.8929, VA=0.8592, TeL=0.9363, TeA=0.8562, LR=0.00013,\n",
      "Epoch 198: TrL=0.0150, TrA=0.9949, VL=0.9156, VA=0.8572, TeL=0.9366, TeA=0.8552, LR=0.00011,\n",
      "Epoch 199: TrL=0.0137, TrA=0.9955, VL=0.9014, VA=0.8577, TeL=0.9375, TeA=0.8557, LR=0.00009,\n",
      "Epoch 200: TrL=0.0165, TrA=0.9943, VL=0.9020, VA=0.8604, TeL=0.9376, TeA=0.8564, LR=0.00007,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "train(model, loaders, optimizer, criterion, epochs=num_epochs, dev=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b6b95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
